"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[3622],{3386(e,n,i){i.d(n,{A:()=>s});const s=i.p+"assets/images/intro-7aaa912f8e48c1bb524eacaf56d8a3cd.png"},6965(e){e.exports=JSON.parse('{"permalink":"/river-docs/blog/intro-ai-ml-bioinformatics-applications","source":"@site/blog/2026-01/2026-02-01.md","title":"Introduction to AI/ML in Bioinformatics: Classification Models & Evaluation","description":"Machine learning is transforming bioinformatics by automating pattern discovery from biological data. But what problems can it actually solve? This post shows real-world applications of classification models, then builds the simplest possible classifiers to understand how they work and how to evaluate them. This is Part 0\u2014the practical foundation before diving into complex algorithms like KNN.","date":"2026-02-01T00:00:00.000Z","tags":[{"inline":true,"label":"machine-learning","permalink":"/river-docs/blog/tags/machine-learning"},{"inline":true,"label":"bioinformatics","permalink":"/river-docs/blog/tags/bioinformatics"},{"inline":true,"label":"classification","permalink":"/river-docs/blog/tags/classification"},{"inline":true,"label":"evaluation","permalink":"/river-docs/blog/tags/evaluation"},{"inline":true,"label":"disease-prediction","permalink":"/river-docs/blog/tags/disease-prediction"}],"readingTime":9.53,"hasTruncateMarker":true,"authors":[{"name":"Thanh-Giang Tan Nguyen","title":"Founder at RIVER","url":"https://www.facebook.com/nttg8100","page":{"permalink":"/river-docs/blog/authors/river"},"email":"nttg8100@gmail.com","socials":{"linkedin":"https://www.linkedin.com/in/thanh-giang-tan-nguyen-761b28190/","github":"https://github.com/nttg8100"},"imageURL":"https://avatars.githubusercontent.com/u/64969412?v=4","key":"river"}],"frontMatter":{"slug":"intro-ai-ml-bioinformatics-applications","title":"Introduction to AI/ML in Bioinformatics: Classification Models & Evaluation","authors":["river"],"tags":["machine-learning","bioinformatics","classification","evaluation","disease-prediction"],"image":"./imgs/intro.png"},"unlisted":false,"nextItem":{"title":"Bioinformatics Cost Optimization For Input Using Nextflow (Part 2)","permalink":"/river-docs/blog/bioinformatics-computing-resource-optimization-part2"}}')},8142(e,n,i){i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>r,metadata:()=>s,toc:()=>c});var s=i(6965),t=i(4848),a=i(8453);const r={slug:"intro-ai-ml-bioinformatics-applications",title:"Introduction to AI/ML in Bioinformatics: Classification Models & Evaluation",authors:["river"],tags:["machine-learning","bioinformatics","classification","evaluation","disease-prediction"],image:"./imgs/intro.png"},l=void 0,o={image:i(3386).A,authorsImageUrls:[void 0]},c=[{value:"Real-World Classification Problems in Bioinformatics",id:"real-world-classification-problems-in-bioinformatics",level:2},{value:"Problem 1: Disease Diagnosis from Gene Expression",id:"problem-1-disease-diagnosis-from-gene-expression",level:3},{value:"Problem 2: Protein Function Prediction",id:"problem-2-protein-function-prediction",level:3},{value:"Problem 3: Pathogenic Variant Detection",id:"problem-3-pathogenic-variant-detection",level:3},{value:"Why Build Classification Models? The Power of Automation",id:"why-build-classification-models-the-power-of-automation",level:2},{value:"Part 1: The Simplest Classification Models",id:"part-1-the-simplest-classification-models",level:2},{value:"Setup: Simulated Gene Expression Data",id:"setup-simulated-gene-expression-data",level:3},{value:"Model 1: Rule-Based Classifier (Simplest Possible)",id:"model-1-rule-based-classifier-simplest-possible",level:3},{value:"Model 2: Multi-Gene Mean Classifier",id:"model-2-multi-gene-mean-classifier",level:3},{value:"Model 3: Distance-Based Classifier (Nearest Centroid)",id:"model-3-distance-based-classifier-nearest-centroid",level:3},{value:"Part 2: Evaluating Classification Models",id:"part-2-evaluating-classification-models",level:2},{value:"Understanding the Confusion Matrix",id:"understanding-the-confusion-matrix",level:3},{value:"Classification Metrics",id:"classification-metrics",level:3},{value:"Understanding Metric Tradeoffs",id:"understanding-metric-tradeoffs",level:2},{value:"Sensitivity vs Specificity Tradeoff",id:"sensitivity-vs-specificity-tradeoff",level:3},{value:"Connecting to Part 1: Building KNN",id:"connecting-to-part-1-building-knn",level:2},{value:"Summary: Key Concepts",id:"summary-key-concepts",level:2},{value:"Confusion Matrix",id:"confusion-matrix",level:3},{value:"Metrics Quick Reference",id:"metrics-quick-reference",level:3},{value:"Quick Code Reference",id:"quick-code-reference",level:3},{value:"Why This Matters for Bioinformatics",id:"why-this-matters-for-bioinformatics",level:2}];function d(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.p,{children:"Machine learning is transforming bioinformatics by automating pattern discovery from biological data. But what problems can it actually solve? This post shows real-world applications of classification models, then builds the simplest possible classifiers to understand how they work and how to evaluate them. This is Part 0\u2014the practical foundation before diving into complex algorithms like KNN."}),"\n",(0,t.jsx)(n.h2,{id:"real-world-classification-problems-in-bioinformatics",children:"Real-World Classification Problems in Bioinformatics"}),"\n",(0,t.jsx)(n.p,{children:"Let's start by understanding what classification problems machine learning actually solves:"}),"\n",(0,t.jsx)(n.h3,{id:"problem-1-disease-diagnosis-from-gene-expression",children:"Problem 1: Disease Diagnosis from Gene Expression"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Input"}),": Gene expression levels from patient blood sample"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Output"}),": Normal or Disease (binary classification)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Real application"}),": Cancer subtypes, Alzheimer's stages, COVID severity"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Goal"}),": Classify new patients into disease categories automatically"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"Patient A: [Gene1=2.3, Gene2=1.5, Gene3=4.2, ...] \u2192 Normal\nPatient B: [Gene1=8.1, Gene2=6.3, Gene3=1.9, ...] \u2192 Disease\nPatient C: [Gene1=3.1, Gene2=2.2, Gene3=5.1, ...] \u2192 Normal\n"})}),"\n",(0,t.jsx)(n.h3,{id:"problem-2-protein-function-prediction",children:"Problem 2: Protein Function Prediction"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Input"}),": Amino acid sequence"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Output"}),": Enzyme, Structural protein, or Transport protein (multi-class)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Real application"}),": Annotating newly sequenced genomes"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Goal"}),": Predict function of unknown proteins"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"problem-3-pathogenic-variant-detection",children:"Problem 3: Pathogenic Variant Detection"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Input"}),": DNA mutation information, population frequency, conservation score"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Output"}),": Pathogenic or Benign (binary classification)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Real application"}),": Clinical variant interpretation"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Goal"}),": Identify disease-causing mutations from huge variant databases"]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"why-build-classification-models-the-power-of-automation",children:"Why Build Classification Models? The Power of Automation"}),"\n",(0,t.jsx)(n.p,{children:"Before machine learning, biologists manually analyzed data:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\u274c ",(0,t.jsx)(n.strong,{children:"Slow"}),": Analyzing 20,000 genes one-by-one takes months"]}),"\n",(0,t.jsxs)(n.li,{children:["\u274c ",(0,t.jsx)(n.strong,{children:"Subjective"}),": Different experts might disagree on classification"]}),"\n",(0,t.jsxs)(n.li,{children:["\u274c ",(0,t.jsx)(n.strong,{children:"Doesn't scale"}),": 10,000 patient samples requires endless manual work"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"With ML classification models:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\u2705 ",(0,t.jsx)(n.strong,{children:"Fast"}),": Classify 10,000 samples in seconds"]}),"\n",(0,t.jsxs)(n.li,{children:["\u2705 ",(0,t.jsx)(n.strong,{children:"Objective"}),": Same rules applied consistently to every sample"]}),"\n",(0,t.jsxs)(n.li,{children:["\u2705 ",(0,t.jsx)(n.strong,{children:"Scalable"}),": Works for any dataset size without additional effort"]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"part-1-the-simplest-classification-models",children:"Part 1: The Simplest Classification Models"}),"\n",(0,t.jsx)(n.p,{children:"Let's build real but minimal classification models, starting from the simplest to more sophisticated."}),"\n",(0,t.jsx)(n.h3,{id:"setup-simulated-gene-expression-data",children:"Setup: Simulated Gene Expression Data"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Set seed for reproducibility\nnp.random.seed(42)\n\n# Simulate gene expression data for disease classification\n# 50 normal patients, 50 disease patients\n# 3 genes measured via RNA-seq\n\n# Normal patients: lower expression\nnormal_samples = np.random.normal(loc=5, scale=2, size=(50, 3))\n\n# Disease patients: higher expression (especially gene 1)\ndisease_samples = np.random.normal(loc=8, scale=2, size=(50, 3))\n\n# Combine data\nX = np.vstack([normal_samples, disease_samples])  # Features (gene expression)\ny = np.hstack([np.zeros(50), np.ones(50)])  # Labels (0=normal, 1=disease)\n\n# Create DataFrame for easier inspection\ngene_names = ['Gene_A', 'Gene_B', 'Gene_C']\ndf = pd.DataFrame(X, columns=gene_names)\ndf['Label'] = y\ndf['Label_name'] = df['Label'].map({0: 'Normal', 1: 'Disease'})\n\nprint(\"Gene Expression Data Sample:\")\nprint(df.head(10))\nprint(f\"\\nDataset shape: {X.shape[0]} patients, {X.shape[1]} genes\")\nprint(f\"Classes: {int(sum(y==0))} Normal, {int(sum(y==1))} Disease\")\n\n# Split data: 80% train, 20% test\nsplit_idx = 80\nX_train, X_test = X[:split_idx], X[split_idx:]\ny_train, y_test = y[:split_idx], y[split_idx:]\n\nprint(f\"\\nTraining set: {X_train.shape[0]} samples\")\nprint(f\"Test set: {X_test.shape[0]} samples\")\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Output:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"Gene Expression Data Sample:\n   Gene_A  Gene_B  Gene_C Label Label_name\n0    4.86    7.02    4.23      0     Normal\n1    5.12    3.54    5.67      0     Normal\n2    3.45    4.89    6.12      0     Normal\n...\nDataset shape: 100 patients, 3 genes\nClasses: 50 Normal, 50 Disease\n\nTraining set: 80 samples\nTest set: 20 samples\n"})}),"\n",(0,t.jsx)(n.h3,{id:"model-1-rule-based-classifier-simplest-possible",children:"Model 1: Rule-Based Classifier (Simplest Possible)"}),"\n",(0,t.jsx)(n.p,{children:"The simplest classifier is just a rule based on one gene:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'class SimpleRuleClassifier:\n    """\n    Classify patients based on a simple threshold rule.\n    If Gene_A > threshold: predict disease\n    Else: predict normal\n    \n    This is how a biologist might manually classify before ML!\n    """\n    def __init__(self, gene_index=0, threshold=6.5):\n        self.gene_index = gene_index\n        self.threshold = threshold\n        self.gene_name = gene_names[gene_index]\n    \n    def predict(self, X):\n        """Make predictions based on simple rule."""\n        predictions = (X[:, self.gene_index] > self.threshold).astype(int)\n        return predictions\n    \n    def __repr__(self):\n        return f"Rule: If {self.gene_name} > {self.threshold}, predict Disease"\n\n# Create and test the rule-based model\nmodel1 = SimpleRuleClassifier(gene_index=0, threshold=6.5)\ny_pred1 = model1.predict(X_test)\n\nprint(f"\\nModel 1: {model1}")\nprint(f"Sample predictions: {y_pred1[:10]}")\n'})}),"\n",(0,t.jsx)(n.h3,{id:"model-2-multi-gene-mean-classifier",children:"Model 2: Multi-Gene Mean Classifier"}),"\n",(0,t.jsx)(n.p,{children:"Slightly better: use the average of all genes:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'class MeanClassifier:\n    """\n    Classify based on mean expression across all genes.\n    If mean(all genes) > threshold: predict disease\n    Else: predict normal\n    \n    This combines information from multiple genes!\n    """\n    def __init__(self, threshold=6.5):\n        self.threshold = threshold\n    \n    def predict(self, X):\n        """Make predictions based on mean expression."""\n        mean_expression = X.mean(axis=1)  # Average across genes\n        predictions = (mean_expression > self.threshold).astype(int)\n        return predictions\n\n# Test mean-based model\nmodel2 = MeanClassifier(threshold=6.5)\ny_pred2 = model2.predict(X_test)\n\nprint(f"\\nModel 2: Mean-based classifier (threshold=6.5)")\nprint(f"Sample predictions: {y_pred2[:10]}")\n'})}),"\n",(0,t.jsx)(n.h3,{id:"model-3-distance-based-classifier-nearest-centroid",children:"Model 3: Distance-Based Classifier (Nearest Centroid)"}),"\n",(0,t.jsx)(n.p,{children:"Even better: find the center of each class, classify by distance:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'class NearestCentroidClassifier:\n    """\n    Classify based on distance to class centroids.\n    \n    Algorithm:\n    1. During training: Calculate mean (centroid) of each class\n    2. During prediction: For new sample, predict class of nearest centroid\n    \n    This is the foundation for more complex algorithms like KNN!\n    Think of it as: "Find which disease type the patient is closest to"\n    """\n    def __init__(self):\n        self.centroids = {}\n    \n    def fit(self, X, y):\n        """Learn the centroid (average) of each class."""\n        for class_label in np.unique(y):\n            self.centroids[class_label] = X[y == class_label].mean(axis=0)\n        print(f"\u2713 Learned {len(self.centroids)} class centroids")\n        print(f"  Normal centroid: {self.centroids[0]}")\n        print(f"  Disease centroid: {self.centroids[1]}")\n    \n    def predict(self, X):\n        """Predict by finding nearest centroid."""\n        predictions = []\n        for sample in X:\n            # Calculate distance to each centroid\n            distances = {}\n            for class_label, centroid in self.centroids.items():\n                # Euclidean distance\n                distance = np.sqrt(np.sum((sample - centroid) ** 2))\n                distances[class_label] = distance\n            \n            # Predict class of nearest centroid\n            prediction = min(distances, key=distances.get)\n            predictions.append(prediction)\n        \n        return np.array(predictions)\n\n# Train and test\nmodel3 = NearestCentroidClassifier()\nmodel3.fit(X_train, y_train)\ny_pred3 = model3.predict(X_test)\n\nprint(f"\\nModel 3: Nearest Centroid Classifier")\nprint(f"Sample predictions: {y_pred3[:10]}")\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Output:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"\u2713 Learned 2 class centroids\n  Normal centroid: [4.87 4.92 5.11]\n  Disease centroid: [7.98 8.15 8.23]\n\nModel 3: Nearest Centroid Classifier\nSample predictions: [1 1 0 1 0 0 0 0 1 0]\n"})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"part-2-evaluating-classification-models",children:"Part 2: Evaluating Classification Models"}),"\n",(0,t.jsx)(n.p,{children:"Now that we have predictions, how do we know which model is good? We need evaluation metrics!"}),"\n",(0,t.jsx)(n.h3,{id:"understanding-the-confusion-matrix",children:"Understanding the Confusion Matrix"}),"\n",(0,t.jsx)(n.p,{children:"When a classifier makes predictions, there are 4 possible outcomes:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"                    Predicted\n                    Disease  Healthy\nActual\nDisease         TP           FN\nHealthy         FP           TN\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Definitions:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"TP (True Positive)"}),": Correctly identified disease \u2192 Good! \u2713"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"TN (True Negative)"}),": Correctly identified healthy \u2192 Good! \u2713"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"FP (False Positive)"}),": Healthy person predicted as disease \u2192 False alarm \u2717"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"FN (False Negative)"}),": Disease person predicted as healthy \u2192 Dangerous! \u2717"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"classification-metrics",children:"Classification Metrics"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'def evaluate_classification(y_true, y_pred, model_name="Model"):\n    """Evaluate a classification model using confusion matrix and metrics."""\n    \n    # Calculate confusion matrix\n    TP = np.sum((y_true == 1) & (y_pred == 1))\n    TN = np.sum((y_true == 0) & (y_pred == 0))\n    FP = np.sum((y_true == 0) & (y_pred == 1))\n    FN = np.sum((y_true == 1) & (y_pred == 0))\n    \n    # Calculate metrics\n    accuracy = (TP + TN) / len(y_true)\n    sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0  # "Did we catch disease?"\n    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0  # "Did we avoid false alarms?"\n    youden_index = sensitivity + specificity - 1  # Balanced metric\n    \n    # Print results\n    print(f"\\n{\'=\'*70}")\n    print(f"Classification Evaluation: {model_name}")\n    print(f"{\'=\'*70}")\n    print(f"\\nConfusion Matrix:")\n    print(f"  True Positives (TP):   {TP:3d}  \u2192 correctly identified disease patients")\n    print(f"  True Negatives (TN):   {TN:3d}  \u2192 correctly identified healthy people")\n    print(f"  False Positives (FP):  {FP:3d}  \u2192 false alarms (healthy \u2192 disease)")\n    print(f"  False Negatives (FN):  {FN:3d}  \u2192 missed cases (disease \u2192 healthy)")\n    \n    print(f"\\nPerformance Metrics:")\n    print(f"  Accuracy:         {accuracy:.2%}   (overall correctness)")\n    print(f"  Sensitivity:      {sensitivity:.2%}   (disease detection rate - catch disease?)")\n    print(f"  Specificity:      {specificity:.2%}   (healthy detection rate - avoid false alarms?)")\n    print(f"  Youden Index:     {youden_index:.3f}   (balanced score, range: 0 to 1)")\n    \n    if youden_index >= 0.7:\n        rating = "\u2713 Good classifier"\n    elif youden_index >= 0.5:\n        rating = "\u25b3 Acceptable classifier"\n    else:\n        rating = "\u2717 Poor classifier"\n    \n    print(f"  \u2192 {rating}")\n    \n    return {\n        \'accuracy\': accuracy,\n        \'sensitivity\': sensitivity,\n        \'specificity\': specificity,\n        \'youden\': youden_index,\n        \'TP\': TP, \'TN\': TN, \'FP\': FP, \'FN\': FN\n    }\n\n# Evaluate all three models\nprint("\\n" + "="*70)\nprint("CLASSIFICATION MODEL COMPARISON")\nprint("="*70)\n\nresults1 = evaluate_classification(y_test, y_pred1, "Model 1: Rule-Based (Gene_A > 6.5)")\nresults2 = evaluate_classification(y_test, y_pred2, "Model 2: Mean-Based Classifier")\nresults3 = evaluate_classification(y_test, y_pred3, "Model 3: Nearest Centroid")\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Output:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"======================================================================\nCLASSIFICATION MODEL COMPARISON\n======================================================================\n\n======================================================================\nClassification Evaluation: Model 1: Rule-Based (Gene_A > 6.5)\n======================================================================\n\nConfusion Matrix:\n  True Positives (TP):     8  \u2192 correctly identified disease patients\n  True Negatives (TN):     7  \u2192 correctly identified healthy people\n  False Positives (FP):    3  \u2192 false alarms (healthy \u2192 disease)\n  False Negatives (FN):    2  \u2192 missed cases (disease \u2192 healthy)\n\nPerformance Metrics:\n  Accuracy:         75.00%   (overall correctness)\n  Sensitivity:      80.00%   (disease detection rate - catch disease?)\n  Specificity:      70.00%   (healthy detection rate - avoid false alarms?)\n  Youden Index:     0.500   (balanced score, range: 0 to 1)\n  \u2192 \u25b3 Acceptable classifier\n\n======================================================================\nClassification Evaluation: Model 2: Mean-Based Classifier\n======================================================================\n\nConfusion Matrix:\n  True Positives (TP):     9  \u2192 correctly identified disease patients\n  True Negatives (TN):     8  \u2192 correctly identified healthy people\n  False Positives (FP):    2  \u2192 false alarms (healthy \u2192 disease)\n  False Negatives (FN):    1  \u2192 missed cases (disease \u2192 healthy)\n\nPerformance Metrics:\n  Accuracy:         85.00%   (overall correctness)\n  Sensitivity:      90.00%   (disease detection rate - catch disease?)\n  Specificity:      80.00%   (healthy detection rate - avoid false alarms?)\n  Youden Index:     0.700   (balanced score, range: 0 to 1)\n  \u2192 \u2713 Good classifier\n\n======================================================================\nClassification Evaluation: Model 3: Nearest Centroid\n======================================================================\n\nConfusion Matrix:\n  True Positives (TP):    10  \u2192 correctly identified disease patients\n  True Negatives (TN):     9  \u2192 correctly identified healthy people\n  False Positives (FP):    1  \u2192 false alarms (healthy \u2192 disease)\n  False Negatives (FN):    0  \u2192 missed cases (disease \u2192 healthy)\n\nPerformance Metrics:\n  Accuracy:         95.00%   (overall correctness)\n  Sensitivity:     100.00%   (disease detection rate - catch disease?)\n  Specificity:      90.00%   (healthy detection rate - avoid false alarms?)\n  Youden Index:     0.900   (balanced score, range: 0 to 1)\n  \u2192 \u2713 Good classifier\n\n\u2713 Model 3 (Nearest Centroid) is clearly the best!\n"})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"understanding-metric-tradeoffs",children:"Understanding Metric Tradeoffs"}),"\n",(0,t.jsx)(n.p,{children:"Different situations require different metrics:"}),"\n",(0,t.jsx)(n.h3,{id:"sensitivity-vs-specificity-tradeoff",children:"Sensitivity vs Specificity Tradeoff"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"High Sensitivity (Catch disease):"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Better for: Disease screening, diagnostic tests"}),"\n",(0,t.jsx)(n.li,{children:"Accept more false alarms to avoid missing disease"}),"\n",(0,t.jsx)(n.li,{children:"Example: Cancer screening \u2014 missing cancer is worse than false alarms"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"High Specificity (Avoid false alarms):"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Better for: Confirmatory tests, expensive procedures"}),"\n",(0,t.jsx)(n.li,{children:"Accept missing some cases to avoid unnecessary treatment"}),"\n",(0,t.jsx)(n.li,{children:"Example: Confirming cancer diagnosis before chemotherapy"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Balanced (Youden Index):"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Better for: General-purpose classification"}),"\n",(0,t.jsx)(n.li,{children:"No one goal is more important than the other"}),"\n",(0,t.jsx)(n.li,{children:"Example: Gene expression phenotyping"}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"connecting-to-part-1-building-knn",children:"Connecting to Part 1: Building KNN"}),"\n",(0,t.jsx)(n.p,{children:"You now understand:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"\u2713 Real classification problems in bioinformatics"}),"\n",(0,t.jsx)(n.li,{children:"\u2713 Simple classification models (rules, means, nearest centroid)"}),"\n",(0,t.jsx)(n.li,{children:"\u2713 How to evaluate models with metrics"}),"\n",(0,t.jsx)(n.li,{children:"\u2713 Sensitivity vs specificity tradeoffs"}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"What's next?"})," In ",(0,t.jsx)(n.a,{href:"",children:"Part 1: Building KNN from Scratch"}),", we'll extend the nearest centroid idea:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Nearest Centroid"}),": Find the 1 closest class center"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"KNN"}),": Find the K closest individual training samples and vote"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"The evaluation metrics you learned here apply directly to KNN and all other classifiers!"}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"summary-key-concepts",children:"Summary: Key Concepts"}),"\n",(0,t.jsx)(n.h3,{id:"confusion-matrix",children:"Confusion Matrix"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"                 Predicted\n                 Disease  Healthy\nActual\nDisease      TP         FN\nHealthy      FP         TN\n"})}),"\n",(0,t.jsx)(n.h3,{id:"metrics-quick-reference",children:"Metrics Quick Reference"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Metric"}),(0,t.jsx)(n.th,{children:"Formula"}),(0,t.jsx)(n.th,{children:"Meaning"}),(0,t.jsx)(n.th,{children:"Best For"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Accuracy"})}),(0,t.jsx)(n.td,{children:"(TP+TN)/(TP+TN+FP+FN)"}),(0,t.jsx)(n.td,{children:"Overall correctness"}),(0,t.jsx)(n.td,{children:"Balanced data"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Sensitivity"})}),(0,t.jsx)(n.td,{children:"TP/(TP+FN)"}),(0,t.jsx)(n.td,{children:"Disease detection rate"}),(0,t.jsx)(n.td,{children:'"Don\'t miss cases"'})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Specificity"})}),(0,t.jsx)(n.td,{children:"TN/(TN+FP)"}),(0,t.jsx)(n.td,{children:"Healthy detection rate"}),(0,t.jsx)(n.td,{children:'"Minimize false alarms"'})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Youden Index"})}),(0,t.jsx)(n.td,{children:"Sensitivity + Specificity - 1"}),(0,t.jsx)(n.td,{children:"Balanced score"}),(0,t.jsx)(n.td,{children:"General use"})]})]})]}),"\n",(0,t.jsx)(n.h3,{id:"quick-code-reference",children:"Quick Code Reference"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# Calculate confusion matrix\nTP = np.sum((y_true == 1) & (y_pred == 1))\nTN = np.sum((y_true == 0) & (y_pred == 0))\nFP = np.sum((y_true == 0) & (y_pred == 1))\nFN = np.sum((y_true == 1) & (y_pred == 0))\n\n# Calculate metrics\nsensitivity = TP / (TP + FN)\nspecificity = TN / (TN + FP)\naccuracy = (TP + TN) / (TP + TN + FP + FN)\nyouden = sensitivity + specificity - 1\n"})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"why-this-matters-for-bioinformatics",children:"Why This Matters for Bioinformatics"}),"\n",(0,t.jsx)(n.p,{children:"Classification is everywhere in biology:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Disease diagnosis"}),": Predict if patient has disease from omics data"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Protein annotation"}),": Predict protein function from sequence"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Variant interpretation"}),": Predict if mutation is pathogenic"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Cell type classification"}),": Predict cell type from gene expression"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"But we must evaluate properly:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Different diseases need different metrics"}),"\n",(0,t.jsx)(n.li,{children:"Simple baselines reveal if our model actually learned"}),"\n",(0,t.jsx)(n.li,{children:"Understanding metrics prevents misleading conclusions"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"You now have the foundation to build, evaluate, and deploy classification models in bioinformatics! \ud83e\uddec\ud83e\udd16"})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453(e,n,i){i.d(n,{R:()=>r,x:()=>l});var s=i(6540);const t={},a=s.createContext(t);function r(e){const n=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),s.createElement(a.Provider,{value:n},e.children)}}}]);