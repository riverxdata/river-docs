"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[1888],{788(e,n,t){t.r(n),t.d(n,{assets:()=>o,contentTitle:()=>r,default:()=>h,frontMatter:()=>l,metadata:()=>i,toc:()=>c});var i=t(799),s=t(4848),a=t(8453);const l={slug:"bioinformatics-computing-resource-optimization-part2",title:"Bioinformatics Cost Optimization For Input Using Nextflow (Part 2)",authors:["river"],tags:["nextflow","hpc","workflow-optimization"],image:"./imgs_17_01/nextflow_optimization.svg"},r=void 0,o={image:t(7941).A,authorsImageUrls:[void 0]},c=[{value:"AWS CLI",id:"aws-cli",level:2},{value:"Install",id:"install",level:3},{value:"Start S3 service",id:"start-s3-service",level:3},{value:"Testing Download Independently",id:"testing-download-independently",level:3},{value:"Download 10k files",id:"download-10k-files",level:4},{value:"Download tarfile",id:"download-tarfile",level:4},{value:"Fuse based system",id:"fuse-based-system",level:4},{value:"Recap",id:"recap",level:3},{value:"Nextflow integration",id:"nextflow-integration",level:2},{value:"Workflow",id:"workflow",level:3},{value:"Modules",id:"modules",level:3},{value:"COUNT_FILES",id:"count_files",level:4},{value:"COUNT_FILES_TAR",id:"count_files_tar",level:4},{value:"Remaining materials",id:"remaining-materials",level:3},{value:"Testing",id:"testing",level:3},{value:"Running with 10k files as input",id:"running-with-10k-files-as-input",level:4},{value:"Running with 1 large file, untar in the process",id:"running-with-1-large-file-untar-in-the-process",level:4},{value:"Magic improvement",id:"magic-improvement",level:3},{value:"Recap",id:"recap-1",level:3},{value:"Genomics England case studies",id:"genomics-england-case-studies",level:2},{value:"Issues",id:"issues",level:3},{value:"Workflow and modules",id:"workflow-and-modules",level:3},{value:"Inputs",id:"inputs",level:3},{value:"Benchmark",id:"benchmark",level:3},{value:"Recap",id:"recap-2",level:2},{value:"Performance Analysis",id:"performance-analysis",level:3},{value:"Optimization Strategies",id:"optimization-strategies",level:3},{value:"Practical Applications",id:"practical-applications",level:3},{value:"Key Takeaways",id:"key-takeaways",level:3}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.p,{children:"Amazon S3 (Simple Storage Service) is built around the concept of storing files as objects, where each file is identified by a unique key rather than a traditional file system path. While this architecture offers scalability and flexibility for storage, it can present challenges when used as a standard file system, especially in bioinformatics workflows. When running Nextflow with S3 as the input/output backend, there are trade-offs to consider\u2014particularly when dealing with large numbers of small files. In such cases, Nextflow may spend significant time handling downloads and uploads via the AWS CLI v2, which can impact overall workflow performance. Let\u2019s explore this in more detail."}),"\n",(0,s.jsx)(n.h2,{id:"aws-cli",children:"AWS CLI"}),"\n",(0,s.jsx)(n.h3,{id:"install",children:"Install"}),"\n",(0,s.jsx)(n.p,{children:"AWS CLI is the command line tools that helps work with AWS services. With nextflow, it can help for downloading inputs, uploading outputs.\nTo install this tool and the tutorial on this blog, clone this repo. The repo uses the pixi and dokcer to quickly setup"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"git clone git@github.com:nttg8100/nextflow-cost-optimization.git\ncd nextflow-cost-optimization\npixi shell\nwhich aws\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Explain ",(0,s.jsx)(n.code,{children:"Makefile"}),", the below, we will run to start the docker service, upload files and the tar file of 10k files that can be used for benchmarking later"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'aws-config: start-minio\n\texport AWS_ACCESS_KEY_ID="minioadmin"; \\\n\texport AWS_SECRET_ACCESS_KEY="minioadmin"; \\\n\texport AWS_DEFAULT_REGION="us-east-1"; \\\n\texport AWS_ENDPOINT_URL="http://localhost:9000" ; \\\n\tsleep 10 && aws s3 mb s3://io-benchmark --endpoint-url http://localhost:9000\n\nresults/tarball.tar:\n\t@mkdir -p results/tarball\n\t@count=10000; size=1M; index=1; \\\n\tfor k in $$(seq $$count); do \\\n\t\tdd if=/dev/zero of=results/tarball/$${size}-$${index}-$$k.data bs=1 count=0 seek=$$size; \\\n\tdone\n\ttar -cvf results/tarball.tar -C results/tarball .\n\nupload-tar:\n\taws s3 cp results/tarball.tar s3://io-benchmark/ --endpoint-url http://localhost:9000\n\nupload-10k-files:\n\taws s3 cp results/tarball  s3://io-benchmark/tarball --endpoint-url http://localhost:9000 --recursive\n'})}),"\n",(0,s.jsx)(n.h3,{id:"start-s3-service",children:"Start S3 service"}),"\n",(0,s.jsx)(n.p,{children:"Now you are ready to work with S3 object storage, this one will launch the minio, the simulated compatible S3 service with AWS. That will help to minimize the error related to your local computer and the remote bucket. This will create bucket called io-benchmark. Also simulated a lot of small files that we use later for proof of concept of this issue"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"make aws-config\n"})}),"\n",(0,s.jsx)(n.p,{children:"To test the s3 service"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# export env\nexport AWS_ACCESS_KEY_ID="minioadmin"\nexport AWS_SECRET_ACCESS_KEY="minioadmin"\nexport AWS_DEFAULT_REGION="us-east-1"\nexport AWS_ENDPOINT_URL="http://localhost:9000"\n# configure threads\naws configure set default.s3.max_concurrent_requests 8\n# test bucket\naws s3 ls  --endpoint-url http://localhost:9000\n# 1026-01-27 10:29:58 io-benchmark\n'})}),"\n",(0,s.jsx)(n.h3,{id:"testing-download-independently",children:"Testing Download Independently"}),"\n",(0,s.jsxs)(n.p,{children:["The above file content is the ",(0,s.jsx)(n.code,{children:"Makefile"})," which simulates to create 1GB in total for a folder with 10k files, each file is 1MB. Nextflow is usually has the slow performance for input by 2 main reason:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Verify download for each file"}),"\n",(0,s.jsx)(n.li,{children:"Calculate inputs cache for all small files"}),"\n"]}),"\n",(0,s.jsx)(n.admonition,{type:"tip",children:(0,s.jsx)(n.p,{children:"It will create the additional tar file of these 10k files, that I will show you later why we create it and how it make your workflow easier"})}),"\n",(0,s.jsx)(n.p,{children:"Without nextflow intervection, we want to test how long does it takes using aws cli v2 only"}),"\n",(0,s.jsx)(n.h4,{id:"download-10k-files",children:"Download 10k files"}),"\n",(0,s.jsx)(n.p,{children:"Run this command to download"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'make upload-10k-files\nfor i in {1..3}; do /usr/bin/time -f "%e" aws s3 cp s3://io-benchmark/tarball ./tarball --endpoint-url http://localhost:9000 --recursive 2>&1 | tail -n 1; rm -rf ./tarball; done\n'})}),"\n",(0,s.jsx)(n.p,{children:"The stderr shows that it takes around 110 seconds to download files"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"110.62\n109.62\n110.59\n"})}),"\n",(0,s.jsx)(n.h4,{id:"download-tarfile",children:"Download tarfile"}),"\n",(0,s.jsx)(n.p,{children:"Run this command to download, it will be much faster"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'make upload-tar\nfor i in {1..3}; do /usr/bin/time -f "%e" aws s3 cp s3://io-benchmark/tarball.tar . --endpoint-url http://localhost:9000 2>&1 | tail -n 1; rm -rf ./tarball.tar; done\n'})}),"\n",(0,s.jsx)(n.p,{children:"The stderr shows that it takes less than 30 seconds to download this large file."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"27.50\n26.96\n25.35\n"})}),"\n",(0,s.jsx)(n.p,{children:'However, we need to have the small file inside, we can use pipe "|" to do it when we download file quickly'}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"for i in {1..3}; do /usr/bin/time -f \"%e\" bash -c 'mkdir -p tarball && aws s3 cp s3://io-benchmark/tarball.tar - --endpoint-url http://localhost:9000 | tar -xvf - -C tarball' 2>&1 | tail -n 1; rm -rf ./tarball; done\n"})}),"\n",(0,s.jsx)(n.p,{children:"The stderr shows that it takes less than 35 seconds to download and untar to get all small files"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"33.43\n31.80\n33.20\n"})}),"\n",(0,s.jsx)(n.h4,{id:"fuse-based-system",children:"Fuse based system"}),"\n",(0,s.jsx)(n.p,{children:"Beside using the aws command to download individual files or tar file, using fuse based system is the alternative approach."}),"\n",(0,s.jsx)(n.admonition,{type:"tip",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"For small files: FUSE enables applications to access individual files on demand without needing to download an entire archive or use complex commands, reducing overhead and making access fast and convenient."}),"\n",(0,s.jsx)(n.li,{children:"For large files: FUSE filesystems can fetch only the needed data chunks, allowing for efficient partial reads, sequential streaming, and avoiding unnecessary full downloads."}),"\n",(0,s.jsx)(n.li,{children:"General advantage: Since FUSE exposes cloud storage as a standard directory tree, workflows and tools that use local files work seamlessly, enabling parallel access and integration with caching and prefetching optimizations."}),"\n"]})}),"\n",(0,s.jsx)(n.p,{children:"It can be used for using in the application that works with the large file or the folder contains many small files but it does not load entirely. For example, we annotate the variant for whole exome data but the annotation database\nis used for entire genome. We can use the tool to get only a few annotated variants region. Beside, distributed engine with fuse based system can be useful for distributed loading."}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"Makefile"})," to quickly install mount-s3 via pixi. It will mount the whole bucket to the ",(0,s.jsx)(n.code,{children:"/mnt/vep_cache"}),". This mount point is named after ",(0,s.jsx)(n.code,{children:"vep"})," later it will be used direclty with VEP annotation example"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"mount-s3-vep-cache: ${HOME}/.pixi/bin/pixi\n\tmkdir -p ./mnt/vep_cache\n\tmkdir -p ./mnt/tmp\n\t${HOME}/.pixi/bin/pixi run -e mount mount-s3 --endpoint-url http://localhost:9000 --region us-east-1 --force-path-style io-benchmark ./mnt/vep_cache --read-only --cache ./mnt/tmp --max-threads 8\n"})}),"\n",(0,s.jsx)(n.p,{children:"Run this command to allow mount the remote s3 bucket"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"make mount-s3-vep-cache\n# check\ndf\n# Filesystem                            1K-blocks      Used     Available Use% Mounted on\n# udev                                  131907828         0     131907828   0% /dev\n# tmpfs                                  26401936      3052      26398884   1% /run\n# /dev/mapper/ubuntu--vg-ubuntu--lv     980760096 936881112       2913808 100% /\n# tmpfs                                 132009668         0     132009668   0% /dev/shm\n# tmpfs                                      5120         0          5120   0% /run/lock\n# tmpfs                                 132009668         0     132009668   0% /run/qemu\n# /dev/loop0                                65408     65408             0 100% /snap/core20/2682\n# /dev/loop1                                65408     65408             0 100% /snap/core20/2686\n# /dev/loop2                                75776     75776             0 100% /snap/core22/2216\n# /dev/loop3                                75776     75776             0 100% /snap/core22/2292\n# /dev/loop4                                93696     93696             0 100% /snap/lxd/35819\n# /dev/loop5                                93696     93696             0 100% /snap/lxd/36918\n# /dev/loop6                                52224     52224             0 100% /snap/snapd/25577\n# /dev/loop7                                49280     49280             0 100% /snap/snapd/25935\n# /dev/nvme0n1p2                          1992552    433904       1437408  24% /boot\n# /dev/nvme0n1p1                          1098632      6228       1092404   1% /boot/efi\n# controller-01:/home                   476973568 349766144     106714624  77% /home\n# tmpfs                                  26401932         4      26401928   1% /run/user/1000\n# io-benchmark                      1099511627776         0 1099511627776   0% /scratch/data/nextflow-cost-optimization/mnt/vep_cache\n"})}),"\n",(0,s.jsx)(n.p,{children:"Now we can use this to simply download 10k files"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"for i in {1..3}; do /usr/bin/time -f \"%e\" bash -c 'cp -r ./mnt/vep_cache/tarball tarball ' 2>&1 | tail -n 1; rm -rf ./tarball; done\n"})}),"\n",(0,s.jsx)(n.p,{children:"The stderr shows that it takes less than 45 seconds to download small files"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"44.94\n46.06\n45.46\n"})}),"\n",(0,s.jsx)(n.p,{children:"Again, download only 10 GB tar file to see how it work"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"for i in {1..3}; do /usr/bin/time -f \"%e\" bash -c 'mkdir -p tarball && cp ./mnt/vep_cache/tarball.tar tarball' 2>&1 | tail -n 1; rm -rf ./tarball; done\n"})}),"\n",(0,s.jsx)(n.p,{children:"The stderr shows that it takes less than 45 seconds to download small files"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"15.60\n15.37\n15.74\n"})}),"\n",(0,s.jsx)(n.p,{children:"Again, download only 10 GB tar file to see how it work"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"for i in {1..3}; do /usr/bin/time -f \"%e\" bash -c 'mkdir -p tarball && cat ./mnt/vep_cache/tarball.tar|tar -xvf - -C tarball' 2>&1 | tail -n 1; rm -rf ./tarball; done\n"})}),"\n",(0,s.jsx)(n.p,{children:"The stderr shows that it takes less than 45 seconds to download small files"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"19.68\n21.86\n20.31\n"})}),"\n",(0,s.jsx)(n.h3,{id:"recap",children:"Recap"}),"\n",(0,s.jsx)(n.p,{children:"Here is a summary table of the different approaches for downloading 10k small files (1GB total) from S3, with their typical performance and recommended use cases:"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Method"}),(0,s.jsx)(n.th,{children:"Download Time (s)"}),(0,s.jsx)(n.th,{children:"Pros"}),(0,s.jsx)(n.th,{children:"Cons"}),(0,s.jsx)(n.th,{children:"When to Use"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"AWS CLI (recursive, 10k files)"})}),(0,s.jsx)(n.td,{children:"~110"}),(0,s.jsx)(n.td,{children:"Simple, no extra setup"}),(0,s.jsx)(n.td,{children:"Very slow for many small files"}),(0,s.jsx)(n.td,{children:"Rarely; only for small numbers of files"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"AWS CLI (tarball)"})}),(0,s.jsx)(n.td,{children:"~27"}),(0,s.jsx)(n.td,{children:"Fastest for single large file"}),(0,s.jsx)(n.td,{children:"Needs pre-tarring and untarring step"}),(0,s.jsx)(n.td,{children:"When you can bundle files as tar"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"AWS CLI (tarball + untar via pipe)"})}),(0,s.jsx)(n.td,{children:"~33"}),(0,s.jsx)(n.td,{children:"Fast, single download + extraction"}),(0,s.jsx)(n.td,{children:"Needs tar/untar logic"}),(0,s.jsx)(n.td,{children:"When workflow can handle tar extraction"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"FUSE (cp -r 10k files)"})}),(0,s.jsx)(n.td,{children:"~45"}),(0,s.jsx)(n.td,{children:"Transparent, works like local FS"}),(0,s.jsx)(n.td,{children:"Needs FUSE setup, not always fastest"}),(0,s.jsx)(n.td,{children:"When random access or partial reads are needed"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"FUSE (cp tarball)"})}),(0,s.jsx)(n.td,{children:"~15"}),(0,s.jsx)(n.td,{children:"Fastest for large file, transparent access"}),(0,s.jsx)(n.td,{children:"Needs FUSE setup"}),(0,s.jsx)(n.td,{children:"For large files, or when tarball is available"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"FUSE (cat tarball | tar -xvf -)"})}),(0,s.jsx)(n.td,{children:"~20"}),(0,s.jsx)(n.td,{children:"Fast, combines FUSE and streaming untar"}),(0,s.jsx)(n.td,{children:"Needs FUSE setup, tar logic"}),(0,s.jsx)(n.td,{children:"For large archives with extraction"})]})]})]}),"\n",(0,s.jsxs)(n.admonition,{type:"info",children:[(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Recommendations:"})}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"For many small files, avoid direct recursive downloads; use tarballs or FUSE-based solutions."}),"\n",(0,s.jsx)(n.li,{children:"Use tarball + untar (via pipe) for best performance if you can bundle files."}),"\n",(0,s.jsx)(n.li,{children:"FUSE is ideal for workflows needing random access or partial reads, or when you can't change file structure."}),"\n",(0,s.jsx)(n.li,{children:"Nextflow (v25.04+) improves small file handling, but bundling or FUSE still offers significant gains for large numbers of files."}),"\n"]})]}),"\n",(0,s.jsx)(n.h2,{id:"nextflow-integration",children:"Nextflow integration"}),"\n",(0,s.jsx)(n.h3,{id:"workflow",children:"Workflow"}),"\n",(0,s.jsx)(n.p,{children:"We will simply run the workflow below that will accept the inputs from S3, download to use in this process and count the number of files inside"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"include { COUNT_FILES }  from './modules/count_files_tar.nf'\ninclude { COUNT_FILES_TAR } from './modules/count_files_tar.nf'\n\nworkflow {\n    main:        \n        // benchmark files input\n        // normal files\n        if (params.benchmark_input){\n            ch_files = COUNT_FILES(Channel.fromPath(params.inputs).collect())\n        }\n\n        // tarball and untar\n        if (params.benchmark_input_tar){\n            ch_files = COUNT_FILES_TAR(Channel.fromPath(params.inputs).collect())\n        }\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"modules",children:"Modules"}),"\n",(0,s.jsx)(n.h4,{id:"count_files",children:"COUNT_FILES"}),"\n",(0,s.jsx)(n.p,{children:"It will accept a list of files directly from s3"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'process COUNT_FILES {\n    cpus 2\n\n    input:\n    path(file_path)\n\n    script:\n    """\n    ls -lah tarball/**.data|wc -l > num_files.txt\n    """\n}\n'})}),"\n",(0,s.jsx)(n.h4,{id:"count_files_tar",children:"COUNT_FILES_TAR"}),"\n",(0,s.jsx)(n.p,{children:"It will download the tar file first, then inside the process untar later"}),"\n",(0,s.jsx)(n.admonition,{type:"info",children:(0,s.jsx)(n.p,{children:"For downloading file and use pipe to quickly untar will be applied later"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'process COUNT_FILES_ {\n    cpus 2\n\n    input:\n    path(file_path)\n\n    script:\n    """\n    tar -xf ${file_path}\n    ls -lah tarball/**.data|wc -l > num_files.txt\n    """\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"remaining-materials",children:"Remaining materials"}),"\n",(0,s.jsx)(n.p,{children:"It will includes the configuration with nextflow configs, include:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"nextflow.config: Standard config to run with docker, singularity and different platform"}),"\n",(0,s.jsx)(n.li,{children:"nextflow_s3.config: S3 credential for minio storage"}),"\n",(0,s.jsx)(n.li,{children:"nextflow_tar.config: The config that run with the local file later"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"These are the standard setup so I will not explain too much detail here, check at the below structure"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"\u251c\u2500\u2500 benchmark_computing_resource.nf\n\u251c\u2500\u2500 benchmark_input.nf\n\u251c\u2500\u2500 inputs\n\u2502   \u251c\u2500\u2500 1_samplesheet.csv\n\u2502   \u2514\u2500\u2500 full_samplsheet.csv\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 Makefile\n\u251c\u2500\u2500 modules\n\u2502   \u251c\u2500\u2500 count_files.nf\n\u2502   \u251c\u2500\u2500 count_files_tar.nf\n\u2502   \u251c\u2500\u2500 fastp.nf\n\u2502   \u251c\u2500\u2500 fastqc.nf\n\u2502   \u2514\u2500\u2500 vep.nf\n\u251c\u2500\u2500 nextflow.config\n\u251c\u2500\u2500 nextflow_s3.config\n\u251c\u2500\u2500 nextflow_tar.config\n\u251c\u2500\u2500 pixi.lock\n\u251c\u2500\u2500 pixi.toml\n\u251c\u2500\u2500 README.md\n"})}),"\n",(0,s.jsx)(n.h3,{id:"testing",children:"Testing"}),"\n",(0,s.jsxs)(n.p,{children:["Using ",(0,s.jsx)(n.code,{children:"Makefile"})," to simplify the process, it will run with different configuration. For proof of concepts, run once"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'test-input-standard: ${HOME}/.pixi/bin/pixi\n\t${HOME}/.pixi/bin/pixi run -e standard nextflow run benchmark_input.nf \\\n\t\t-c nextflow_s3.config \\\n\t\t--benchmark_input \\\n\t\t--inputs="s3://io-benchmark/tarball"\n\ntest-input-tar: ${HOME}/.pixi/bin/pixi\n\t${HOME}/.pixi/bin/pixi run -e standard nextflow run benchmark_input.nf \\\n\t\t-c nextflow_s3.config \\\n\t\t--benchmark_input_tar \\\n\t\t--inputs="s3://io-benchmark/tmp.txt"\n'})}),"\n",(0,s.jsx)(n.h4,{id:"running-with-10k-files-as-input",children:"Running with 10k files as input"}),"\n",(0,s.jsx)(n.p,{children:"Run the command below"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"time make test-input-standard\n# 42,34s user 7,04s system 77% cpu 1:03,97 total\n\n"})}),"\n",(0,s.jsx)(n.h4,{id:"running-with-1-large-file-untar-in-the-process",children:"Running with 1 large file, untar in the process"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"time make test-input-tar\n# 11,80s user 3,42s system 66% cpu 22,965 total\n"})}),"\n",(0,s.jsx)(n.h3,{id:"magic-improvement",children:"Magic improvement"}),"\n",(0,s.jsx)(n.p,{children:"Although we have show that we can use the single large tar file as input and download inside. However, we have to change the module. Is there any\nconfiguration can help ? Linking with previous section on using pipe after downloading, we can use this config"}),"\n",(0,s.jsxs)(n.p,{children:["What it does it that it will use the same module while the files can be ingested using ",(0,s.jsx)(n.code,{children:"beforeScript"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'process{\n    withName:COUNT_FILES{\n        beforeScript = "mkdir -p tarball && aws s3 cp s3://io-benchmark/tarball.tar - --endpoint-url http://localhost:9000 | tar -xvf - -C tarball"\n    }\n}\n'})}),"\n",(0,s.jsxs)(n.p,{children:["The command to run workflow, we can use a file to keep a place holder for nextflow to accept the input and also we add the config ",(0,s.jsx)(n.code,{children:"nextflow_tar.config"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-Makefile",children:'test-input-tar-pipe: ${HOME}/.pixi/bin/pixi\n\t${HOME}/.pixi/bin/pixi run -e standard nextflow run benchmark_input.nf \\\n\t\t-c nextflow_s3.config -c nextflow_tar.config \\\n\t\t--benchmark_input \\\n\t\t--inputs="s3://io-benchmark/tmp.txt"\n'})}),"\n",(0,s.jsx)(n.p,{children:"Remember to create the temp file and upload to the bucket"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"touch tmp.txt\naws s3 cp tmp.txt  s3://io-benchmark --endpoint-url http://localhost:9000 \n"})}),"\n",(0,s.jsx)(n.p,{children:"Running the new setup"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"time make test-input-tar-pipe\n# 11,33s user 2,85s system 82% cpu 17,166 total\n"})}),"\n",(0,s.jsx)(n.h3,{id:"recap-1",children:"Recap"}),"\n",(0,s.jsx)(n.admonition,{type:"tip",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Using tar file and nextflow config can help reduce x3 times for downloading multiple small files as input"}),"\n",(0,s.jsx)(n.li,{children:"We do not need to modify the existing module"}),"\n"]})}),"\n",(0,s.jsx)(n.h2,{id:"genomics-england-case-studies",children:"Genomics England case studies"}),"\n",(0,s.jsxs)(n.p,{children:["Reference: ",(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"https://aws.amazon.com/blogs/hpc/optimize-nextflow-workflows-on-aws-batch-with-mountpoint-for-amazon-s3/",children:"https://aws.amazon.com/blogs/hpc/optimize-nextflow-workflows-on-aws-batch-with-mountpoint-for-amazon-s3/"})}),"."]}),"\n",(0,s.jsx)(n.h3,{id:"issues",children:"Issues"}),"\n",(0,s.jsx)(n.p,{children:"Now we can consider on what can be the issue that we can face with in the real problem. And how can we apply this\nHere, I found that the blog that how Genomic England can solve the similar issue when they want to use VEP to annotate their variants.\nThe database that they used has many small files with 500GB in total. It will take more time to download data while takes a few minutes to annotate."}),"\n",(0,s.jsx)(n.p,{children:"The pseudo code"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'process VEP {\n\n    input:\n    path(vcf)\n    val(vep_cache)\n\n    script:\n    """\n    vep \\\n        --input_file $vcf \\\n        --fasta $params.human_reference_fasta \\\n        --dir_cache $vep_cache \n    """\n\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"workflow-and-modules",children:"Workflow and modules"}),"\n",(0,s.jsx)(n.p,{children:"Worflow is written simply to use only VEP module. Here to quickly reproduce, all parameters are hard coded"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'include { ENSEMBLVEP_VEP } from \'./modules/vep.nf\'\n\nworkflow {\n    main:\n        ENSEMBLVEP_VEP(\n            Channel.of(tuple([id: \'HCC1395N\'], file("inputs/vep_test_data.vcf.gz"), file("inputs/vep_test_data.vcf.gz.tbi"))), // tuple val(meta), path(vcf), path(custom_extra_files)\n            Channel.value("GRCh38"), // val genome\n            Channel.value("homo_sapiens"), // val species\n            Channel.value(114), // val cache_version\n            Channel.fromPath("s3://io-benchmark/vep_cache"), // path cache\n            Channel.of(tuple([:], [])), // tuple val(meta2), path(fasta)\n            Channel.of([]) // path extra_files\n        )\n}\n'})}),"\n",(0,s.jsxs)(n.p,{children:["VEP module is collected from ",(0,s.jsx)(n.a,{href:"https://github.com/nf-core/sarek/blob/20f41d1ce8b7ba296ee22adc71fe2da2ebcae93f/modules/nf-core/ensemblvep/vep/main.nf",children:(0,s.jsx)(n.strong,{children:"nf-core"})})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'process ENSEMBLVEP_VEP {\n    tag "${meta.id}"\n    label \'process_medium\'\n\n    conda "${moduleDir}/environment.yml"\n    container "${workflow.containerEngine == \'singularity\' && !task.ext.singularity_pull_docker_container\n        ? \'https://community-cr-prod.seqera.io/docker/registry/v2/blobs/sha256/4b/4b5a8c173dc9beaa93effec76b99687fc926b1bd7be47df5d6ce19d7d6b4d6b7/data\'\n        : \'community.wave.seqera.io/library/ensembl-vep:115.2--90ec797ecb088e9a\'}"\n\n    input:\n    tuple val(meta), path(vcf), path(custom_extra_files)\n    val genome\n    val species\n    val cache_version\n    path cache\n    tuple val(meta2), path(fasta)\n    path extra_files\n\n    output:\n    tuple val(meta), path("*.vcf.gz"), emit: vcf, optional: true\n    tuple val(meta), path("*.vcf.gz.tbi"), emit: tbi, optional: true\n    tuple val(meta), path("*.tab.gz"), emit: tab, optional: true\n    tuple val(meta), path("*.json.gz"), emit: json, optional: true\n    path "*.html", emit: report, optional: true\n    path "versions.yml", emit: versions\n\n    when:\n    task.ext.when == null || task.ext.when\n\n    script:\n    def args = task.ext.args ?: \'\'\n    def args2 = task.ext.args2 ?: \'\'\n    def file_extension = args.contains("--vcf") ? \'vcf\' : args.contains("--json") ? \'json\' : args.contains("--tab") ? \'tab\' : \'vcf\'\n    def compress_cmd = args.contains("--compress_output") ? \'\' : \'--compress_output bgzip\'\n    def prefix = task.ext.prefix ?: "${meta.id}"\n    def dir_cache = cache ? "\\${PWD}/${cache}" : "/.vep"\n    def reference = fasta ? "--fasta ${fasta}" : ""\n    def create_index = file_extension == "vcf" ? "tabix ${args2} ${prefix}.${file_extension}.gz" : ""\n    """\n    vep \\\\\n        -i ${vcf} \\\\\n        -o ${prefix}.${file_extension}.gz \\\\\n        ${args} \\\\\n        ${compress_cmd} \\\\\n        ${reference} \\\\\n        --assembly ${genome} \\\\\n        --species ${species} \\\\\n        --cache \\\\\n        --cache_version ${cache_version} \\\\\n        --dir_cache ${dir_cache} \\\\\n        --fork ${task.cpus}\n\n    ${create_index}\n\n    cat <<-END_VERSIONS > versions.yml\n    "${task.process}":\n        ensemblvep: \\$( echo \\$(vep --help 2>&1) | sed \'s/^.*Versions:.*ensembl-vep : //;s/ .*\\$//\')\n        tabix: \\$(echo \\$(tabix -h 2>&1) | sed \'s/^.*Version: //; s/ .*\\$//\')\n    END_VERSIONS\n    """\n\n    stub:\n    def prefix = task.ext.prefix ?: "${meta.id}"\n    def file_extension = args.contains("--vcf") ? \'vcf\' : args.contains("--json") ? \'json\' : args.contains("--tab") ? \'tab\' : \'vcf\'\n    def create_index = file_extension == "vcf" ? "touch ${prefix}.${file_extension}.gz.tbi" : ""\n    """\n    echo "" | gzip > ${prefix}.${file_extension}.gz\n    ${create_index}\n    touch ${prefix}_summary.html\n\n    cat <<-END_VERSIONS > versions.yml\n    "${task.process}":\n        ensemblvep: \\$( echo \\$(vep --help 2>&1) | sed \'s/^.*Versions:.*ensembl-vep : //;s/ .*\\$//\')\n        tabix: \\$(echo \\$(tabix -h 2>&1) | sed \'s/^.*Version: //; s/ .*\\$//\')\n    END_VERSIONS\n    """\n}\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Their solution is showed below\n",(0,s.jsx)(n.img,{alt:"solution",src:t(1171).A+"",width:"1024",height:"811"})]}),"\n",(0,s.jsx)(n.h3,{id:"inputs",children:"Inputs"}),"\n",(0,s.jsxs)(n.p,{children:["The vcf file is prepared on the ",(0,s.jsx)(n.code,{children:"inputs"})," folder, while the vep cache database (25.GB) can be prepared as below on Makefile"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"\nvep/114_GRCh38: ${HOME}/.pixi/bin/pixi\n\tmkdir -p vep\n\ttouch vep/vep_cache\n\tcd vep && ${HOME}/.pixi/bin/pixi run -e core aws s3 --no-sign-request cp s3://annotation-cache/vep_cache/114_GRCh38 114_GRCh38 --recursive\n\nvep/vep_cache.tar: vep/114_GRCh38\n\ttar -cvf vep/vep_cache.tar -C vep/114_GRCh38 .\n\nupload-vep-cache: vep/vep_cache.tar\n\t${HOME}/.pixi/bin/pixi run -e core aws s3 cp vep/114_GRCh38 s3://io-benchmark/ --endpoint-url http://localhost:9000 --recursive\n\t${HOME}/.pixi/bin/pixi run -e core aws s3 cp vep/vep_cache.tar s3://io-benchmark/ --endpoint-url http://localhost:9000\n\t\nmount-s3-vep-cache: ${HOME}/.pixi/bin/pixi\n\tmkdir -p ./mnt/vep_cache\n\tmkdir -p ./mnt/tmp\n\t${HOME}/.pixi/bin/pixi run -e mount mount-s3 --endpoint-url http://localhost:9000 --region us-east-1 --force-path-style io-benchmark ./mnt/vep_cache --read-only --cache ./mnt/tmp --max-threads 8\n"})}),"\n",(0,s.jsx)(n.p,{children:"Simply run"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# download and upload to local s3\nmake upload-vep-cach\n\n# mount to local folder from local s3 via mountpoint-s3 \nmake mount-s3-vep-cache\n"})}),"\n",(0,s.jsx)(n.h3,{id:"benchmark",children:"Benchmark"}),"\n",(0,s.jsxs)(n.p,{children:["Here, I prepred the ",(0,s.jsx)(n.code,{children:"Makefile"})," command to benchmark it quickly"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'test-vep-local: ${HOME}/.pixi/bin/pixi\n\t${HOME}/.pixi/bin/pixi run -e core nextflow run benchmark_vep.nf -profile docker --vep_cache "./vep/114_GRCh38"\n\ntest-vep-mount-cache: ${HOME}/.pixi/bin/pixi\n\t${HOME}/.pixi/bin/pixi run -e core nextflow run benchmark_vep.nf \\\n\t\t-c nextflow_s3.config -c nextflow_vep_mount.config --vep_cache "./mnt/vep_cache/114_GRCh38" -profile docker\n\ntest-vep-direct-s3: ${HOME}/.pixi/bin/pixi\n\t${HOME}/.pixi/bin/pixi run -e core  nextflow run benchmark_vep.nf \\\n\t\t-c nextflow_s3.config --vep_cache "s3://io-benchmark/114_GRCh38" -profile docker\n\ntest-vep-tar-cache: ${HOME}/.pixi/bin/pixi\n\t${HOME}/.pixi/bin/pixi run -e core nextflow run benchmark_vep.nf \\\n\t\t-c nextflow_s3.config -c nextflow_vep_tar.config --vep_cache "s3://io-benchmark/vep_cache" -profile docker\n\ntest-vep-mount-tar: ${HOME}/.pixi/bin/pixi\n\t${HOME}/.pixi/bin/pixi run -e core nextflow run benchmark_vep.nf \\\n\t\t-c nextflow_s3.config -c nextflow_vep_mount_tar.config --vep_cache "s3://io-benchmark/vep_cache" -profile docker\n'})}),"\n",(0,s.jsx)(n.p,{children:"Now we can simply run the relative example test"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"make \\<test-vep-benchmarl>\n"})}),"\n",(0,s.jsx)(n.p,{children:"The following table summarizes the benchmark results for different approaches to accessing the VEP cache database during analysis:"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Method"}),(0,s.jsx)(n.th,{children:"Command"}),(0,s.jsxs)(n.th,{style:{textAlign:"center"},children:["Time (min",":sec",")"]})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Local cache"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"make test-vep-local"})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"2:26.20"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"S3 mount (FUSE)"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"make test-vep-mount-cache"})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"2:31.08"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"S3 mount tar (FUSE)"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"make test-vep-mount-tar"})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"5:57.18"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Direct S3 access"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"make test-vep-direct-s3"})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"6:32.63"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"S3 tar cache"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"make test-vep-tar-cache"})}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"6:02.52"})]})]})]}),"\n",(0,s.jsx)(n.admonition,{type:"info",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"As mentioned above, it does not need to download all of the database cache to annotate for the small vcf region files. That's why mounting the whole database is the best solution in this case"}),"\n",(0,s.jsxs)(n.li,{children:["Replacing the VEP command with ",(0,s.jsx)(n.code,{children:"cp \\$(readlink $cache) tmp -r"})," in the module shows that it takes ",(0,s.jsx)(n.code,{children:"4:16.09"})," to read from mount point and copy the whole folder to the new temporary folder."]}),"\n",(0,s.jsx)(n.li,{children:"Depended on your specific infrastructure, customize based on your need"}),"\n"]})}),"\n",(0,s.jsx)(n.h2,{id:"recap-2",children:"Recap"}),"\n",(0,s.jsx)(n.p,{children:"This comprehensive exploration of Nextflow's S3 integration revealed several key insights:"}),"\n",(0,s.jsx)(n.h3,{id:"performance-analysis",children:"Performance Analysis"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Small files vs Large files"}),": Nextflow handles large single files efficiently but struggles with many small files due to per-file operations"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Download methods"}),": Tar files significantly outperform recursive downloads for small file collections (3x faster)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"FUSE benefits"}),": Mount points provide transparent access with better performance and does not require large disk size for local storage."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"optimization-strategies",children:"Optimization Strategies"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Bundle small files"}),": Use tar archives when dealing with numerous files (10k+ small files)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Stream processing"}),": Pipe extraction for immediate processing without full download"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Smart caching"}),": Leverage FUSE-based caching for databases and reference data"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Choose the right tool"}),": Select download method based on file count and access patterns"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"practical-applications",children:"Practical Applications"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Genomics England case study"}),": FUSE-based VEP annotation"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Bioinformatics pipelines"}),": The principles apply to any workflow using remote data storage"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Cost considerations"}),": Reduced download time + smaller disk size = lower compute costs on cloud platforms."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Profile before optimizing"}),": Measure actual bottlenecks in your specific workflows"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Consider file distribution"}),": Many small \u2260 few large when choosing download strategies"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Use Nextflow v25.04+"}),": Improved small file handling reduces need for workarounds"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Leverage FUSE"}),": Provides transparent access with better performance than CLI tools"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Design for scale"}),": Build workflows that work efficiently with your data characteristics"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Whether you're working with thousands of small files or terabytes of reference data, understanding these patterns helps you design more efficient, cost-effective bioinformatics workflows."})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},799(e){e.exports=JSON.parse('{"permalink":"/river-docs/blog/bioinformatics-computing-resource-optimization-part2","source":"@site/blog/2026-01/2026-01-19.md","title":"Bioinformatics Cost Optimization For Input Using Nextflow (Part 2)","description":"Amazon S3 (Simple Storage Service) is built around the concept of storing files as objects, where each file is identified by a unique key rather than a traditional file system path. While this architecture offers scalability and flexibility for storage, it can present challenges when used as a standard file system, especially in bioinformatics workflows. When running Nextflow with S3 as the input/output backend, there are trade-offs to consider\u2014particularly when dealing with large numbers of small files. In such cases, Nextflow may spend significant time handling downloads and uploads via the AWS CLI v2, which can impact overall workflow performance. Let\u2019s explore this in more detail.","date":"2026-01-19T00:00:00.000Z","tags":[{"inline":true,"label":"nextflow","permalink":"/river-docs/blog/tags/nextflow"},{"inline":true,"label":"hpc","permalink":"/river-docs/blog/tags/hpc"},{"inline":true,"label":"workflow-optimization","permalink":"/river-docs/blog/tags/workflow-optimization"}],"readingTime":17.1,"hasTruncateMarker":true,"authors":[{"name":"Thanh-Giang Tan Nguyen","title":"Founder at RIVER","url":"https://www.facebook.com/nttg8100","page":{"permalink":"/river-docs/blog/authors/river"},"email":"nttg8100@gmail.com","socials":{"linkedin":"https://www.linkedin.com/in/thanh-giang-tan-nguyen-761b28190/","github":"https://github.com/nttg8100"},"imageURL":"https://avatars.githubusercontent.com/u/64969412?v=4","key":"river"}],"frontMatter":{"slug":"bioinformatics-computing-resource-optimization-part2","title":"Bioinformatics Cost Optimization For Input Using Nextflow (Part 2)","authors":["river"],"tags":["nextflow","hpc","workflow-optimization"],"image":"./imgs_17_01/nextflow_optimization.svg"},"unlisted":false,"nextItem":{"title":"Bioinformatics Cost Optimization for Computing Resources Using Nextflow (Part 1)","permalink":"/river-docs/blog/bioinformatics-computing-resource-optimization-part1"}}')},1171(e,n,t){t.d(n,{A:()=>i});const i=t.p+"assets/images/variant_annotation_aws-15d43bdb7357f6f01ab875ad3c907ba6.png"},7941(e,n,t){t.d(n,{A:()=>i});const i=t.p+"assets/images/nextflow_optimization-fe3c2c1da10d871e8be47657ef3626c9.svg"},8453(e,n,t){t.d(n,{R:()=>l,x:()=>r});var i=t(6540);const s={},a=i.createContext(s);function l(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);