"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[7177],{7687(e){e.exports=JSON.parse('{"permalink":"/river-docs/blog/migrate-bash-nextflow-enterprise-pipeline","source":"@site/blog/2026-02/2026-02-11.md","title":"How to Migrate from In-House Pipelines to Enterprise-Level Workflows: A Proven 3-Step Validation Framework","description":"Whether your lab uses bash scripts, Python workflows, Snakemake pipelines, or custom solutions\u2014your in-house pipeline works fine locally. It\'s been running for years. But as your research scales, you face a hard truth: in-house pipelines don\'t scale, aren\'t reproducible across teams, and require constant manual fixes.","date":"2026-02-11T00:00:00.000Z","tags":[{"inline":true,"label":"nextflow","permalink":"/river-docs/blog/tags/nextflow"},{"inline":true,"label":"bash","permalink":"/river-docs/blog/tags/bash"},{"inline":true,"label":"migration","permalink":"/river-docs/blog/tags/migration"},{"inline":true,"label":"reproducibility","permalink":"/river-docs/blog/tags/reproducibility"},{"inline":true,"label":"validation","permalink":"/river-docs/blog/tags/validation"},{"inline":true,"label":"md5","permalink":"/river-docs/blog/tags/md-5"},{"inline":true,"label":"testing","permalink":"/river-docs/blog/tags/testing"},{"inline":true,"label":"enterprise","permalink":"/river-docs/blog/tags/enterprise"}],"readingTime":17.86,"hasTruncateMarker":true,"authors":[{"name":"Thanh-Giang Tan Nguyen","title":"Founder at RIVER","url":"https://www.facebook.com/nttg8100","page":{"permalink":"/river-docs/blog/authors/river"},"email":"nttg8100@gmail.com","socials":{"linkedin":"https://www.linkedin.com/in/thanh-giang-tan-nguyen-761b28190/","github":"https://github.com/nttg8100"},"imageURL":"https://avatars.githubusercontent.com/u/64969412?v=4","key":"river"}],"frontMatter":{"slug":"migrate-bash-nextflow-enterprise-pipeline","title":"How to Migrate from In-House Pipelines to Enterprise-Level Workflows: A Proven 3-Step Validation Framework","authors":["river"],"tags":["nextflow","bash","migration","reproducibility","validation","md5","testing","enterprise"],"image":"./imgs/intro.png"},"unlisted":false,"prevItem":{"title":"Containers on HPC: From Docker to Singularity and Apptainer","permalink":"/river-docs/blog/containers-hpc-docker-singularity-apptainer"},"nextItem":{"title":"Unix Pipes in Bioinformatics: How Streaming Data Reduces Memory and Storage","permalink":"/river-docs/blog/unix-pipes-bioinformatics-streaming-data"}}')},8453(e,n,i){i.d(n,{R:()=>r,x:()=>l});var t=i(6540);const s={},a=t.createContext(s);function r(e){const n=t.useContext(a);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),t.createElement(a.Provider,{value:n},e.children)}},9068(e,n,i){i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>r,metadata:()=>t,toc:()=>d});var t=i(7687),s=i(4848),a=i(8453);const r={slug:"migrate-bash-nextflow-enterprise-pipeline",title:"How to Migrate from In-House Pipelines to Enterprise-Level Workflows: A Proven 3-Step Validation Framework",authors:["river"],tags:["nextflow","bash","migration","reproducibility","validation","md5","testing","enterprise"],image:"./imgs/intro.png"},l=void 0,o={image:i(9831).A,authorsImageUrls:[void 0]},d=[{value:"Why Enterprise Pipelines Matter: The Numbers",id:"why-enterprise-pipelines-matter-the-numbers",level:2},{value:"The Hidden Risk of Pipeline Migration (From Any In-House System)",id:"the-hidden-risk-of-pipeline-migration-from-any-in-house-system",level:2},{value:"Step 1: Establish a Reproducibility Baseline with MD5 Snapshots (From Your Original Pipeline)",id:"step-1-establish-a-reproducibility-baseline-with-md5-snapshots-from-your-original-pipeline",level:2},{value:"1.1 Document Your Original Pipeline (Language/Format Agnostic)",id:"11-document-your-original-pipeline-languageformat-agnostic",level:3},{value:"1.2 Run the Original Pipeline Multiple Times",id:"12-run-the-original-pipeline-multiple-times",level:3},{value:"1.3 Document Non-Deterministic Tools",id:"13-document-non-deterministic-tools",level:3},{value:"1.4 Save the Baseline Manifest",id:"14-save-the-baseline-manifest",level:3},{value:"Step 2: Migrate to Nextflow with Seed Control",id:"step-2-migrate-to-nextflow-with-seed-control",level:2},{value:"2.1 Create Nextflow Processes with Seeds",id:"21-create-nextflow-processes-with-seeds",level:3},{value:"2.2 Create the Main Workflow",id:"22-create-the-main-workflow",level:3},{value:"Step 3: Validate with MD5 Comparison",id:"step-3-validate-with-md5-comparison",level:2},{value:"3.1 Create a Validation Script",id:"31-create-a-validation-script",level:3},{value:"3.2 Run Comparison",id:"32-run-comparison",level:3},{value:"3.3 Detailed Diff Analysis for Failed Files",id:"33-detailed-diff-analysis-for-failed-files",level:3},{value:"3.4 Handle Expected Differences",id:"34-handle-expected-differences",level:3},{value:"Practical Example: Full Migration Walkthrough",id:"practical-example-full-migration-walkthrough",level:2},{value:"Original Bash Pipeline",id:"original-bash-pipeline",level:3},{value:"Nextflow Migration",id:"nextflow-migration",level:3},{value:"Validation Results",id:"validation-results",level:3},{value:"Automating Validation with nf-test (For Nextflow Migrations)",id:"automating-validation-with-nf-test-for-nextflow-migrations",level:2},{value:"Why nf-test is Essential for Nextflow Migrations",id:"why-nf-test-is-essential-for-nextflow-migrations",level:3},{value:"Using nf-test for Migration Validation",id:"using-nf-test-for-migration-validation",level:3},{value:"Example Snapshot File (Automatically Generated)",id:"example-snapshot-file-automatically-generated",level:3},{value:"Full Migration Testing with nf-test",id:"full-migration-testing-with-nf-test",level:3},{value:"Running nf-test in Your Migration Workflow",id:"running-nf-test-in-your-migration-workflow",level:3},{value:"The Complete Migration Workflow with nf-test",id:"the-complete-migration-workflow-with-nf-test",level:3},{value:"Benefits of nf-test Over Manual Validation",id:"benefits-of-nf-test-over-manual-validation",level:3},{value:"Key Considerations and Best Practices",id:"key-considerations-and-best-practices",level:2},{value:"1. Version Pinning",id:"1-version-pinning",level:3},{value:"2. Handling Floating-Point Precision",id:"2-handling-floating-point-precision",level:3},{value:"3. Documentation Template",id:"3-documentation-template",level:3},{value:"Summary: Confidently Migrating Any In-House Pipeline to Enterprise Level",id:"summary-confidently-migrating-any-in-house-pipeline-to-enterprise-level",level:2},{value:"Step 1: Establish Baseline (From Your Original Pipeline)",id:"step-1-establish-baseline-from-your-original-pipeline",level:3},{value:"Step 2: Migrate with Seed Control (To Your Target System)",id:"step-2-migrate-with-seed-control-to-your-target-system",level:3},{value:"Step 3: Validate with Checksums (Automated or Manual)",id:"step-3-validate-with-checksums-automated-or-manual",level:3},{value:"Key Takeaways",id:"key-takeaways",level:3}];function c(e){const n={code:"code",h2:"h2",h3:"h3",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.p,{children:"Whether your lab uses bash scripts, Python workflows, Snakemake pipelines, or custom solutions\u2014your in-house pipeline works fine locally. It's been running for years. But as your research scales, you face a hard truth: in-house pipelines don't scale, aren't reproducible across teams, and require constant manual fixes."}),"\n",(0,s.jsxs)(n.p,{children:["This is where enterprise-level workflow management comes in. But before you migrate your entire pipeline to Nextflow (or any professional workflow manager), you need answers to the hardest question: ",(0,s.jsx)(n.strong,{children:"Will the new pipeline produce identical results?"})]}),"\n",(0,s.jsx)(n.p,{children:"This blog reveals the proven 3-step framework used by production teams to confidently migrate ANY bioinformatics pipeline\u2014regardless of its original format. You'll learn how to establish reproducibility baselines, control for non-deterministic behavior, and validate that your enterprise pipeline is scientifically equivalent to your original work. Plus, we'll show you how nf-test automates this entire validation process when migrating to Nextflow."}),"\n",(0,s.jsx)(n.h2,{id:"why-enterprise-pipelines-matter-the-numbers",children:"Why Enterprise Pipelines Matter: The Numbers"}),"\n",(0,s.jsx)(n.p,{children:"Your lab's in-house pipeline (bash, Python, Snakemake, or custom) might work locally, but it doesn't scale beyond your machine. Here's what changes when you move from in-house to enterprise-level:"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"The In-House Pipeline Problem (Any Format):"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Runs on one person's machine, with one person understanding it"}),"\n",(0,s.jsx)(n.li,{children:"Tool versions undocumented and constantly drift across environments"}),"\n",(0,s.jsx)(n.li,{children:"Non-reproducible results across team members, platforms, or time"}),"\n",(0,s.jsx)(n.li,{children:"Scaling from 10 samples to 1000 means extensive reworking"}),"\n",(0,s.jsx)(n.li,{children:"Impossible to share with collaborators, publish with research, or integrate with institutional compute systems"}),"\n",(0,s.jsx)(n.li,{children:"No audit trail for regulatory or compliance requirements"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Enterprise Pipeline Benefits (Nextflow, Snakemake, or CWL):"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Containerized, version-controlled, self-documenting"}),"\n",(0,s.jsx)(n.li,{children:"Reproducible results to the byte, across any platform (laptop to HPC to cloud)"}),"\n",(0,s.jsx)(n.li,{children:"Scales from 1 sample to 100,000 without modification"}),"\n",(0,s.jsx)(n.li,{children:"Shareable, citable, auditable for regulatory compliance"}),"\n",(0,s.jsx)(n.li,{children:"Integrable with HPC systems, cloud platforms, and institutional data pipelines"}),"\n",(0,s.jsx)(n.li,{children:"Native support for monitoring, logging, and failure recovery"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"The Cost of Staying In-House:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Researcher time spent debugging instead of analyzing: 30-40% of effort"}),"\n",(0,s.jsx)(n.li,{children:"Lost results due to environment changes: $10,000+ per incident"}),"\n",(0,s.jsx)(n.li,{children:'Collaboration delayed by "it works on my machine" problems: weeks per project'}),"\n",(0,s.jsx)(n.li,{children:"Inability to meet publishing reproducibility standards"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"the-hidden-risk-of-pipeline-migration-from-any-in-house-system",children:"The Hidden Risk of Pipeline Migration (From Any In-House System)"}),"\n",(0,s.jsx)(n.p,{children:"Your current pipeline is a black box of institutional knowledge\u2014whether it's bash scripts, Python code, Snakemake, or custom workflows. It was built incrementally, never designed for reproducibility across teams, and probably has undocumented quirks that make it work. You can't just rewrite it in Nextflow and hope for the same results."}),"\n",(0,s.jsxs)(n.p,{children:["The hard truth: ",(0,s.jsx)(n.strong,{children:"60% of bioinformatics pipeline migrations introduce subtle bugs that go undetected for months."})," A variant is called differently. A read is filtered out. A threshold is slightly different. A file is processed in a different order. Biologically, maybe it matters. Scientifically, it's a catastrophe because you can't trace back what changed."]}),"\n",(0,s.jsx)(n.p,{children:"This is why enterprise teams use a validation framework\u2014regardless of whether they're migrating FROM bash, Python, Snakemake, custom C++, or anything else. Before replacing your in-house pipeline with an enterprise system (Nextflow, Snakemake, CWL, etc.), you need:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:'A baseline snapshot (MD5 checksums) of what "correct" looks like from your original pipeline'}),"\n",(0,s.jsx)(n.li,{children:"Explicit control over non-deterministic behavior (hard-coded random seeds)"}),"\n",(0,s.jsx)(n.li,{children:"Byte-for-byte validation that the new pipeline matches the old"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["The framework is the same regardless of source. But the tooling differs based on your target. ",(0,s.jsx)(n.strong,{children:"If you're migrating TO Nextflow, nf-test automates this entire process."})]}),"\n",(0,s.jsx)(n.p,{children:"Let's build that framework."}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"step-1-establish-a-reproducibility-baseline-with-md5-snapshots-from-your-original-pipeline",children:"Step 1: Establish a Reproducibility Baseline with MD5 Snapshots (From Your Original Pipeline)"}),"\n",(0,s.jsx)(n.p,{children:"The first step is creating a \"golden standard\"\u2014verified outputs from your original in-house pipeline (bash, Python, Snakemake, or any format) that you can use as a reference. This baseline is universal and doesn't depend on what you're migrating TO."}),"\n",(0,s.jsx)(n.h3,{id:"11-document-your-original-pipeline-languageformat-agnostic",children:"1.1 Document Your Original Pipeline (Language/Format Agnostic)"}),"\n",(0,s.jsx)(n.p,{children:"Create a comprehensive script that records everything:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\n# original_pipeline.sh - Reference implementation with full documentation\n\nset -euo pipefail\n\n# Configuration\nREFERENCE="/data/reference/hg38.fasta"\nREADS="/data/reads/sample.fastq"\nOUTPUT_DIR="/results/baseline"\nMANIFEST="${OUTPUT_DIR}/manifest.txt"\n\n# Create output directory\nmkdir -p "${OUTPUT_DIR}"\n\n# Record software versions\necho "=== Pipeline Execution Record ===" > "${MANIFEST}"\necho "Date: $(date -Iseconds)" >> "${MANIFEST}"\necho "" >> "${MANIFEST}"\necho "=== Software Versions ===" >> "${MANIFEST}"\necho "bwa: $(bwa 2>&1 | grep Version)" >> "${MANIFEST}"\necho "samtools: $(samtools --version | head -1)" >> "${MANIFEST}"\necho "bcftools: $(bcftools --version | head -1)" >> "${MANIFEST}"\necho "" >> "${MANIFEST}"\n\n# Record input file hashes\necho "=== Input File Checksums ===" >> "${MANIFEST}"\nmd5sum "${REFERENCE}" >> "${MANIFEST}"\nmd5sum "${READS}" >> "${MANIFEST}"\necho "" >> "${MANIFEST}"\n\n# Step 1: Alignment\necho "=== Step 1: BWA Alignment ===" >> "${MANIFEST}"\nbwa mem -t 8 "${REFERENCE}" "${READS}" | \\\n  samtools sort -@ 4 -o "${OUTPUT_DIR}/aligned.bam" -\nmd5sum "${OUTPUT_DIR}/aligned.bam" >> "${MANIFEST}"\necho "aligned.bam: $(md5sum ${OUTPUT_DIR}/aligned.bam | cut -d\' \' -f1)"\n\n# Step 2: Mark Duplicates\necho "=== Step 2: Mark Duplicates ===" >> "${MANIFEST}"\nsamtools markdup "${OUTPUT_DIR}/aligned.bam" "${OUTPUT_DIR}/marked.bam"\nmd5sum "${OUTPUT_DIR}/marked.bam" >> "${MANIFEST}"\necho "marked.bam: $(md5sum ${OUTPUT_DIR}/marked.bam | cut -d\' \' -f1)"\n\n# Step 3: Call Variants\necho "=== Step 3: Call Variants ===" >> "${MANIFEST}"\nbcftools mpileup -f "${REFERENCE}" "${OUTPUT_DIR}/marked.bam" | \\\n  bcftools call -m -o "${OUTPUT_DIR}/variants.vcf"\nmd5sum "${OUTPUT_DIR}/variants.vcf" >> "${MANIFEST}"\necho "variants.vcf: $(md5sum ${OUTPUT_DIR}/variants.vcf | cut -d\' \' -f1)"\n\necho ""\necho "Baseline execution complete. Manifest saved to: ${MANIFEST}"\ncat "${MANIFEST}"\n'})}),"\n",(0,s.jsx)(n.h3,{id:"12-run-the-original-pipeline-multiple-times",children:"1.2 Run the Original Pipeline Multiple Times"}),"\n",(0,s.jsx)(n.p,{children:"Execute the pipeline multiple times with identical inputs to verify determinism:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\n# Verify pipeline reproducibility\n\nRUNS=3\nREFERENCE_DIR="/results/baseline"\n\necho "Running original pipeline $RUNS times..."\n\nfor i in $(seq 1 $RUNS); do\n  OUTPUT_DIR="/results/baseline_run_$i"\n  bash original_pipeline.sh > /tmp/run_$i.log 2>&1\ndone\n\n# Compare outputs\necho ""\necho "=== Reproducibility Check ==="\nmd5sum "${REFERENCE_DIR}/aligned.bam" /results/baseline_run_*/aligned.bam\nmd5sum "${REFERENCE_DIR}/marked.bam" /results/baseline_run_*/marked.bam\nmd5sum "${REFERENCE_DIR}/variants.vcf" /results/baseline_run_*/variants.vcf\n\n# Extract just the checksums and compare\nBASELINE_ALIGNED=$(md5sum "${REFERENCE_DIR}/aligned.bam" | cut -d\' \' -f1)\nBASELINE_MARKED=$(md5sum "${REFERENCE_DIR}/marked.bam" | cut -d\' \' -f1)\nBASELINE_VARIANTS=$(md5sum "${REFERENCE_DIR}/variants.vcf" | cut -d\' \' -f1)\n\necho ""\necho "Baseline checksums:"\necho "  aligned.bam: $BASELINE_ALIGNED"\necho "  marked.bam: $BASELINE_MARKED"\necho "  variants.vcf: $BASELINE_VARIANTS"\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Expected output if pipeline is deterministic:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"98a4d5f8c7b2e9f3a1d6c4b5 /results/baseline/aligned.bam\n98a4d5f8c7b2e9f3a1d6c4b5 /results/baseline_run_1/aligned.bam\n98a4d5f8c7b2e9f3a1d6c4b5 /results/baseline_run_2/aligned.bam\n98a4d5f8c7b2e9f3a1d6c4b5 /results/baseline_run_3/aligned.bam\n\nAll checksums match - Pipeline is deterministic!\n"})}),"\n",(0,s.jsx)(n.h3,{id:"13-document-non-deterministic-tools",children:"1.3 Document Non-Deterministic Tools"}),"\n",(0,s.jsxs)(n.p,{children:["Some bioinformatics tools produce non-deterministic output by design (random seeds, floating-point precision, threading order). ",(0,s.jsx)(n.strong,{children:"Identify and handle them explicitly:"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Tools that need seed control\n# These must be configured with hard-coded seeds\n\n# Example 1: Tools with random sampling (seqtk)\nseqtk sample -s 42 reads.fastq 0.5 > sampled.fastq\n\n# Example 2: Tools with randomized output order (bowtie2 with threading)\nbowtie2 --seed 42 -p 8 -x index -U reads.fastq -S output.sam\n\n# Example 3: Python-based tools with numpy/scipy randomness\npython process.py --seed 42\n\n# Example 4: R-based tools\n# In R script:\nset.seed(42)\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Create a mapping document:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-markdown",children:"# Non-Deterministic Tools in Our Pipeline\n\n| Tool                | Reason                 | Solution             |\n| ------------------- | ---------------------- | -------------------- |\n| seqtk sample        | Random sampling        | Use --seed 42        |\n| bowtie2             | Thread-based shuffling | Use --seed 42        |\n| custom_py_script.py | numpy random           | Set seed in code     |\n| variant_filter.R    | R randomization        | set.seed(42) in code |\n\nAll tools must use hard-coded seeds (42 chosen arbitrarily).\n"})}),"\n",(0,s.jsx)(n.h3,{id:"14-save-the-baseline-manifest",children:"1.4 Save the Baseline Manifest"}),"\n",(0,s.jsx)(n.p,{children:"Create a versioned baseline that future pipelines must match:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# baseline_checksums.txt\n# Generated: 2026-02-11T10:30:00Z\n# Pipeline Version: 1.0\n# Tools: bwa-0.7.17, samtools-1.18, bcftools-1.18\n\naligned.bam:98a4d5f8c7b2e9f3a1d6c4b5e2f3g4h5\nmarked.bam: a2b3c4d5e6f7g8h9i0j1k2l3m4n5o6p7\nvariants.vcf: x9y8z7w6v5u4t3s2r1q0p9o8n7m6l5k4\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"step-2-migrate-to-nextflow-with-seed-control",children:"Step 2: Migrate to Nextflow with Seed Control"}),"\n",(0,s.jsx)(n.p,{children:"Now migrate your bash pipeline to Nextflow while maintaining deterministic behavior through seed control."}),"\n",(0,s.jsx)(n.h3,{id:"21-create-nextflow-processes-with-seeds",children:"2.1 Create Nextflow Processes with Seeds"}),"\n",(0,s.jsx)(n.p,{children:"Convert each bash step to a Nextflow process, explicitly setting seeds:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-groovy",children:'// modules/bwa_align.nf\nprocess BWA_ALIGN {\n    tag "$meta.id"\n    label \'process_high\'\n    \n    container \'community.wave.seqera.io/library/bwa_samtools:56c9f8d5201889a4\'\n    \n    input:\n    tuple val(meta), path(reads)\n    path reference\n    path reference_index\n    \n    output:\n    tuple val(meta), path("*.bam"), emit: bam\n    path "versions.yml", emit: versions\n    \n    script:\n    """\n    # Seed control: bwa uses thread-based order\n    # To maintain determinism, use single-threaded or\n    # use sorted output from samtools\n    \n    bwa mem \\\\\n        -t ${task.cpus} \\\\\n        ${reference} \\\\\n        ${reads} | \\\\\n        samtools sort \\\\\n            -@ ${task.cpus} \\\\\n            -o ${meta.id}.bam \\\\\n            -\n    \n    # Verify output\n    samtools view -c ${meta.id}.bam\n    \n    cat <<-END_VERSIONS > versions.yml\n    "${task.process}":\n        bwa: \\$(echo \\$(bwa 2>&1) | sed \'s/^.*Version: //; s/Contact:.*\\$//\')\n        samtools: \\$(echo \\$(samtools --version 2>&1) | sed \'s/^.*samtools //; s/Using.*\\$//\')\n    END_VERSIONS\n    """\n}\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-groovy",children:'// modules/mark_duplicates.nf\nprocess MARK_DUPLICATES {\n    tag "$meta.id"\n    label \'process_medium\'\n    \n    container \'community.wave.seqera.io/library/samtools:1.18\'\n    \n    input:\n    tuple val(meta), path(bam)\n    \n    output:\n    tuple val(meta), path("*marked.bam"), emit: bam\n    path "versions.yml", emit: versions\n    \n    script:\n    """\n    # samtools markdup is deterministic when input is sorted\n    samtools markdup \\\\\n        -M \\\\\n        ${bam} \\\\\n        ${meta.id}.marked.bam\n    \n    cat <<-END_VERSIONS > versions.yml\n    "${task.process}":\n        samtools: \\$(echo \\$(samtools --version 2>&1) | sed \'s/^.*samtools //; s/Using.*\\$//\')\n    END_VERSIONS\n    """\n}\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-groovy",children:'// modules/call_variants.nf\nprocess CALL_VARIANTS {\n    tag "$meta.id"\n    label \'process_medium\'\n    \n    container \'community.wave.seqera.io/library/bcftools:1.18\'\n    \n    input:\n    tuple val(meta), path(bam)\n    path reference\n    \n    output:\n    tuple val(meta), path("*.vcf"), emit: vcf\n    path "versions.yml", emit: versions\n    \n    script:\n    """\n    # bcftools is deterministic when output format is sorted\n    bcftools mpileup \\\\\n        -f ${reference} \\\\\n        ${bam} | \\\\\n        bcftools call \\\\\n            -m \\\\\n            -o ${meta.id}.variants.vcf\n    \n    # Sort VCF for reproducibility\n    vcf-sort ${meta.id}.variants.vcf > ${meta.id}.variants.sorted.vcf\n    mv ${meta.id}.variants.sorted.vcf ${meta.id}.variants.vcf\n    \n    cat <<-END_VERSIONS > versions.yml\n    "${task.process}":\n        bcftools: \\$(echo \\$(bcftools --version 2>&1) | sed \'s/^.*bcftools //; s/ .*\\$//\')\n    END_VERSIONS\n    """\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"22-create-the-main-workflow",children:"2.2 Create the Main Workflow"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-groovy",children:"// nextflow.config\nprocess {\n    shell = ['/bin/bash', '-euo', 'pipefail']\n    \n    withLabel: process_high {\n        cpus = 8\n        memory = { 16.GB * task.attempt }\n        time = { 4.h * task.attempt }\n    }\n    \n    withLabel: process_medium {\n        cpus = 4\n        memory = { 8.GB * task.attempt }\n        time = { 2.h * task.attempt }\n    }\n}\n\nprofiles {\n    docker {\n        docker.enabled = true\n    }\n    singularity {\n        singularity.enabled = true\n    }\n    standard {\n        process.executor = 'local'\n    }\n}\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-groovy",children:"// main.nf\ninclude { BWA_ALIGN } from './modules/bwa_align'\ninclude { MARK_DUPLICATES } from './modules/mark_duplicates'\ninclude { CALL_VARIANTS } from './modules/call_variants'\n\nworkflow {\n    // Input channel\n    input_samples = Channel\n        .fromPath(params.input_dir + '/*.fastq')\n        .map { file -> \n            def meta = [id: file.baseName]\n            tuple(meta, file)\n        }\n    \n    // Reference files\n    reference = file(params.reference)\n    reference_index = file(params.reference + '.bwt')\n    \n    // Run pipeline\n    BWA_ALIGN(input_samples, reference, reference_index)\n    MARK_DUPLICATES(BWA_ALIGN.out.bam)\n    CALL_VARIANTS(MARK_DUPLICATES.out.bam, reference)\n}\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:"# params.yaml\ninput_dir: './data/reads'\nreference: './data/reference/hg38.fasta'\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"step-3-validate-with-md5-comparison",children:"Step 3: Validate with MD5 Comparison"}),"\n",(0,s.jsx)(n.p,{children:"After running the Nextflow pipeline, systematically compare outputs with the baseline."}),"\n",(0,s.jsx)(n.h3,{id:"31-create-a-validation-script",children:"3.1 Create a Validation Script"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\n# validate_migration.sh - Compare Nextflow outputs with bash baseline\n\nset -euo pipefail\n\nBASELINE_DIR="/results/baseline"\nNEXTFLOW_DIR="/results/nextflow"\nVALIDATION_REPORT="/results/validation_report.txt"\n\n{\n    echo "=== Pipeline Migration Validation Report ==="\n    echo "Generated: $(date -Iseconds)"\n    echo ""\n    \n    # Function to compare checksums\n    compare_file() {\n        local filename=$1\n        local baseline="${BASELINE_DIR}/${filename}"\n        local migrated="${NEXTFLOW_DIR}/${filename}"\n        \n        if [ ! -f "$baseline" ]; then\n            echo "BASELINE MISSING: $filename"\n            return 1\n        fi\n        \n        if [ ! -f "$migrated" ]; then\n            echo "MIGRATED MISSING: $filename"\n            return 1\n        fi\n        \n        local baseline_md5=$(md5sum "$baseline" | cut -d\' \' -f1)\n        local migrated_md5=$(md5sum "$migrated" | cut -d\' \' -f1)\n        \n        if [ "$baseline_md5" == "$migrated_md5" ]; then\n            echo "PASS: $filename"\n            echo "   MD5: $baseline_md5"\n            return 0\n        else\n            echo "FAIL: $filename"\n            echo "   Baseline MD5: $baseline_md5"\n            echo "   Migrated MD5: $migrated_md5"\n            return 1\n        fi\n    }\n    \n    # Compare all output files\n    echo "=== File Comparisons ==="\n    declare -i pass=0\n    declare -i fail=0\n    \n    for file in aligned.bam marked.bam variants.vcf; do\n        if compare_file "$file"; then\n            ((pass++))\n        else\n            ((fail++))\n        fi\n    done\n    \n    echo ""\n    echo "=== Summary ==="\n    echo "Passed: $pass"\n    echo "Failed: $fail"\n    echo ""\n    \n     if [ $fail -eq 0 ]; then\n         echo "VALIDATION SUCCESSFUL: All outputs match baseline!"\n         exit 0\n     else\n         echo "VALIDATION FAILED: $fail file(s) differ from baseline"\n         exit 1\n     fi\n    \n} | tee "$VALIDATION_REPORT"\n'})}),"\n",(0,s.jsx)(n.h3,{id:"32-run-comparison",children:"3.2 Run Comparison"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\n# Run the migration validation\n\n# First, ensure baseline exists\nif [ ! -d "/results/baseline" ]; then\n    echo "Error: Baseline not found. Run original_pipeline.sh first."\n    exit 1\nfi\n\n# Run Nextflow pipeline\necho "Running Nextflow migration..."\nnextflow run main.nf \\\n    --input_dir ./data/reads \\\n    --reference ./data/reference/hg38.fasta \\\n    -profile docker \\\n    -resume\n\n# Validate outputs\necho ""\necho "Validating migration..."\nbash validate_migration.sh\n'})}),"\n",(0,s.jsx)(n.h3,{id:"33-detailed-diff-analysis-for-failed-files",children:"3.3 Detailed Diff Analysis for Failed Files"}),"\n",(0,s.jsx)(n.p,{children:"If checksums don't match, investigate the difference:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\n# deep_diff.sh - Detailed analysis of differences\n\nBASELINE=$1\nMIGRATED=$2\nFILENAME=$(basename "$BASELINE")\n\necho "=== Detailed Comparison: $FILENAME ==="\n\n# 1. Check file sizes\nBASELINE_SIZE=$(stat -f%z "$BASELINE" 2>/dev/null || stat -c%s "$BASELINE")\nMIGRATED_SIZE=$(stat -f%z "$MIGRATED" 2>/dev/null || stat -c%s "$MIGRATED")\n\necho "File sizes:"\necho "  Baseline: $BASELINE_SIZE bytes"\necho "  Migrated: $MIGRATED_SIZE bytes"\n\nif [ "$BASELINE_SIZE" != "$MIGRATED_SIZE" ]; then\n    echo "  Size difference detected"\nfi\n\n# 2. For BAM files: compare with samtools\nif [[ "$FILENAME" == *.bam ]]; then\n    echo ""\n    echo "BAM file analysis:"\n    \n    # Compare read counts\n    BASELINE_READS=$(samtools view -c "$BASELINE")\n    MIGRATED_READS=$(samtools view -c "$MIGRATED")\n    echo "  Baseline reads: $BASELINE_READS"\n    echo "  Migrated reads: $MIGRATED_READS"\n    \n    if [ "$BASELINE_READS" != "$MIGRATED_READS" ]; then\n        echo "  Read count mismatch!"\n    fi\n    \n    # Compare first 10 reads\n    echo ""\n    echo "  First 10 reads comparison:"\n    echo "  --- Baseline ---"\n    samtools view "$BASELINE" | head -10\n    echo "  --- Migrated ---"\n    samtools view "$MIGRATED" | head -10\nfi\n\n# 3. For VCF files: compare variants\nif [[ "$FILENAME" == *.vcf ]]; then\n    echo ""\n    echo "VCF file analysis:"\n    \n    # Count variants (skip header)\n    BASELINE_VARS=$(grep -v "^#" "$BASELINE" | wc -l)\n    MIGRATED_VARS=$(grep -v "^#" "$MIGRATED" | wc -l)\n    \n    echo "  Baseline variants: $BASELINE_VARS"\n    echo "  Migrated variants: $MIGRATED_VARS"\n    \n    if [ "$BASELINE_VARS" != "$MIGRATED_VARS" ]; then\n        echo "  Variant count mismatch!"\n    fi\n    \n    # Show first differences\n    echo ""\n    echo "  First 5 variants (baseline vs migrated):"\n    diff <(grep -v "^#" "$BASELINE" | head -5) <(grep -v "^#" "$MIGRATED" | head -5) || true\nfi\n\n# 4. Compare line-by-line for text files\nif [[ "$FILENAME" == *.vcf || "$FILENAME" == *.txt ]]; then\n    echo ""\n    echo "Line-by-line diff (first 20 differences):"\n    diff "$BASELINE" "$MIGRATED" | head -20 || true\nfi\n'})}),"\n",(0,s.jsx)(n.h3,{id:"34-handle-expected-differences",children:"3.4 Handle Expected Differences"}),"\n",(0,s.jsx)(n.p,{children:"Some differences are acceptable. Document them:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-markdown",children:"# Known Acceptable Differences Between Bash and Nextflow\n\n## 1. Tool Versions\n- Bash: bwa 0.7.17, samtools 1.18\n- Nextflow: bwa 0.7.17, samtools 1.18\n\u2192 If versions match, output should be identical\n\n## 2. Threading Order (BAM files)\n- Threading can affect read order in BAM files\n- Solution: Use `samtools sort` or deterministic sort\n- Verification: Extract and compare SAM headers + sort order\n\n## 3. VCF Header Timestamps\n- VCF files may have different generation timestamps\n- Solution: Strip headers before comparison\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# Compare VCF ignoring header differences\ncompare_vcf_body() {\n    local baseline=$1\n    local migrated=$2\n    \n    diff \\\n        <(grep -v "^##" "$baseline" | grep -v "^#CHROM" | sort) \\\n        <(grep -v "^##" "$migrated" | grep -v "^#CHROM" | sort)\n}\n\n# Compare BAM files by extracting SAM\ncompare_bam_content() {\n    local baseline=$1\n    local migrated=$2\n    \n    diff \\\n        <(samtools view "$baseline" | sort -k1,1) \\\n        <(samtools view "$migrated" | sort -k1,1)\n}\n'})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"practical-example-full-migration-walkthrough",children:"Practical Example: Full Migration Walkthrough"}),"\n",(0,s.jsx)(n.p,{children:"Let's follow a complete migration scenario:"}),"\n",(0,s.jsx)(n.h3,{id:"original-bash-pipeline",children:"Original Bash Pipeline"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\n# variant_calling_pipeline.sh\n\nset -euo pipefail\n\nSAMPLE="sample_001"\nREFERENCE="/ref/hg38.fasta"\nREADS="/data/${SAMPLE}.fastq.gz"\nOUTPUT_DIR="/results/bash_original"\n\nmkdir -p "$OUTPUT_DIR"\n\n# Step 1: Alignment\nbwa mem -t 8 "$REFERENCE" <(gunzip -c "$READS") | \\\n    samtools sort -@ 4 -o "$OUTPUT_DIR/${SAMPLE}.aligned.bam" -\n\n# Step 2: Mark Duplicates\nsamtools markdup "$OUTPUT_DIR/${SAMPLE}.aligned.bam" \\\n    "$OUTPUT_DIR/${SAMPLE}.marked.bam"\n\n# Step 3: Index\nsamtools index "$OUTPUT_DIR/${SAMPLE}.marked.bam"\n\n# Step 4: Call variants\nbcftools mpileup -f "$REFERENCE" "$OUTPUT_DIR/${SAMPLE}.marked.bam" | \\\n    bcftools call -m -o "$OUTPUT_DIR/${SAMPLE}.vcf"\n\n# Generate checksums\ncd "$OUTPUT_DIR"\nmd5sum *.bam *.vcf > checksums.txt\n'})}),"\n",(0,s.jsx)(n.h3,{id:"nextflow-migration",children:"Nextflow Migration"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-groovy",children:"// main.nf - Migrated to Nextflow\n\nworkflow VARIANT_CALLING {\n    Channel\n        .fromPath(params.reads)\n        .map { file -> [file.baseName, file] }\n        .set { input_reads }\n    \n    BWA_ALIGN(input_reads, params.reference)\n    MARK_DUPLICATES(BWA_ALIGN.out.bam)\n    CALL_VARIANTS(MARK_DUPLICATES.out.bam, params.reference)\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"validation-results",children:"Validation Results"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"$ bash validate_migration.sh\n\n=== Pipeline Migration Validation Report ===\nGenerated: 2026-02-11T15:45:30Z\n\n=== File Comparisons ===\nPASS: sample_001.aligned.bam\n   MD5: 98a4d5f8c7b2e9f3a1d6c4b5e2f3g4h5\nPASS: sample_001.marked.bam\n   MD5: a2b3c4d5e6f7g8h9i0j1k2l3m4n5o6p7\nPASS: sample_001.vcf\n   MD5: x9y8z7w6v5u4t3s2r1q0p9o8n7m6l5k4\n\n=== Summary ===\nPassed: 3\nFailed: 0\n\nVALIDATION SUCCESSFUL: All outputs match baseline!\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"automating-validation-with-nf-test-for-nextflow-migrations",children:"Automating Validation with nf-test (For Nextflow Migrations)"}),"\n",(0,s.jsxs)(n.p,{children:["The manual validation approach works for ANY in-house pipeline migration. But if you're specifically migrating TO Nextflow, there's a better way: ",(0,s.jsx)(n.strong,{children:"nf-test"}),"."]}),"\n",(0,s.jsx)(n.p,{children:"nf-test is a powerful testing framework built specifically for Nextflow pipelines. It automates the entire MD5 snapshot and validation workflow, making migration validation effortless and reproducible."}),"\n",(0,s.jsx)(n.h3,{id:"why-nf-test-is-essential-for-nextflow-migrations",children:"Why nf-test is Essential for Nextflow Migrations"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Manual validation approach:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Generate baseline checksums manually"}),"\n",(0,s.jsx)(n.li,{children:"Create custom validation scripts"}),"\n",(0,s.jsx)(n.li,{children:"Maintain separate comparison logic"}),"\n",(0,s.jsx)(n.li,{children:"Hard to share with team members"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"nf-test approach:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Generates snapshots automatically"}),"\n",(0,s.jsx)(n.li,{children:"Version-controls snapshots in git"}),"\n",(0,s.jsx)(n.li,{children:"Built-in MD5 comparison"}),"\n",(0,s.jsx)(n.li,{children:"Runs in CI/CD pipelines"}),"\n",(0,s.jsx)(n.li,{children:"Team-friendly: snapshots are tracked in git"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"using-nf-test-for-migration-validation",children:"Using nf-test for Migration Validation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-groovy",children:'// tests/modules/bwa_align.nf.test\n\nnextflow_process {\n    name "Test BWA_ALIGN"\n    script "modules/bwa_align.nf"\n    process "BWA_ALIGN"\n    \n    test("Should align reads to reference") {\n        when {\n            process {\n                input[0] = [[id: "sample1"], file("data/reads.fastq")]\n                input[1] = file("data/reference.fasta")\n                input[2] = file("data/reference.fasta.bwt")\n            }\n        }\n        \n        then {\n            assertAll(\n                { assert process.success },\n                { assert snapshot(process.out.bam).match() },\n                { assert path(process.out.bam[0][1]).exists() }\n            )\n        }\n    }\n}\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"What happens:"})}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"First run: nf-test generates a snapshot of BAM file MD5 checksums"}),"\n",(0,s.jsxs)(n.li,{children:["Snapshot is saved in ",(0,s.jsx)(n.code,{children:"tests/modules/bwa_align.nf.test.snap"})]}),"\n",(0,s.jsx)(n.li,{children:"Subsequent runs: nf-test compares outputs against the snapshot"}),"\n",(0,s.jsx)(n.li,{children:"If anything changes: nf-test reports the difference"}),"\n",(0,s.jsxs)(n.li,{children:["Update snapshots with: ",(0,s.jsx)(n.code,{children:"nf-test test tests/modules/bwa_align.nf.test --update-snapshot"})," when intentional changes are made"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"example-snapshot-file-automatically-generated",children:"Example Snapshot File (Automatically Generated)"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:'# tests/modules/bwa_align.nf.test.snap\n\n{\n  "Should align reads to reference": {\n    "content": [\n      {\n        "0": [\n          [\n            {\n              "id": "sample1"\n            },\n            "sample1.bam:98a4d5f8c7b2e9f3a1d6c4b5e2f3g4h5"\n          }\n        ],\n        "bam": [\n          [\n            {\n              "id": "sample1"\n            },\n            "sample1.bam:98a4d5f8c7b2e9f3a1d6c4b5e2f3g4h5"\n          ]\n        ]\n      }\n    ],\n    "timestamp": "2026-02-11T15:45:30Z"\n  }\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"full-migration-testing-with-nf-test",children:"Full Migration Testing with nf-test"}),"\n",(0,s.jsx)(n.p,{children:"Create comprehensive tests for your entire pipeline:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-groovy",children:'// tests/workflows/variant_calling.nf.test\n\nnextflow_workflow {\n    name "Test Complete Variant Calling Pipeline"\n    script "workflows/variant_calling.nf"\n    workflow "VARIANT_CALLING"\n    \n    test("Complete pipeline: reads to variants") {\n        when {\n            workflow {\n                input[0] = [[id: "sample1"], file("data/reads.fastq.gz")]\n            }\n        }\n        \n        then {\n            assertAll(\n                { assert workflow.success },\n                // Snapshot bam output\n                { assert snapshot(workflow.out.bam).match() },\n                // Snapshot vcf output\n                { assert snapshot(workflow.out.vcf).match() },\n                // Verify intermediate files\n                { assert path(workflow.out.bam[0][1]).exists() },\n                { assert path(workflow.out.vcf[0][1]).exists() }\n            )\n        }\n    }\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"running-nf-test-in-your-migration-workflow",children:"Running nf-test in Your Migration Workflow"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Generate initial snapshots from your Nextflow pipeline\nnf-test test tests/main.nf.test --update-snapshot\n\n# Compare against baseline (this is your validation step 3!)\nnf-test test tests/main.nf.test\n\n# If tests fail, review the diff\n# If diff is intentional, update snapshots\nnf-test test tests/main.nf.test --update-snapshot\n\n# Run specific test file\nnf-test test tests/workflows/variant_calling.nf.test\n\n# Run in CI/CD to catch regressions\n# .github/workflows/test.yml\n- name: Test Nextflow Pipeline\n  run: nf-test test tests/ --profile docker\n"})}),"\n",(0,s.jsx)(n.h3,{id:"the-complete-migration-workflow-with-nf-test",children:"The Complete Migration Workflow with nf-test"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Step 1 (Original Pipeline):"})," Generate baseline MD5 snapshots (same as before)"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Step 2 (Migrate to Nextflow):"})," Write Nextflow pipeline + nf-test tests"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Step 3 (Validate with nf-test):"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Generate initial snapshots from migrated Nextflow pipeline\nnf-test test tests/main.nf.test --update-snapshot\n\n# Run: nf-test test tests/main.nf.test\n# nf-test automatically compares against baseline!\n"})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"benefits-of-nf-test-over-manual-validation",children:"Benefits of nf-test Over Manual Validation"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Aspect"}),(0,s.jsx)(n.th,{children:"Manual Validation"}),(0,s.jsx)(n.th,{children:"nf-test"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Snapshot generation"})}),(0,s.jsx)(n.td,{children:"Manual scripting"}),(0,s.jsx)(n.td,{children:"Automatic"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Version control"})}),(0,s.jsx)(n.td,{children:"External files"}),(0,s.jsx)(n.td,{children:"Git-tracked"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Team collaboration"})}),(0,s.jsx)(n.td,{children:"Share scripts"}),(0,s.jsx)(n.td,{children:"Share snapshots"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Regression detection"})}),(0,s.jsx)(n.td,{children:"Manual comparison"}),(0,s.jsx)(n.td,{children:"Automatic CI/CD"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Update process"})}),(0,s.jsx)(n.td,{children:"Rerun scripts"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"nf-test test --update-snapshot"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Documentation"})}),(0,s.jsx)(n.td,{children:"Separate docs"}),(0,s.jsx)(n.td,{children:"Tests are docs"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"Maintenance"})}),(0,s.jsx)(n.td,{children:"High effort"}),(0,s.jsx)(n.td,{children:"Low effort"})]})]})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"key-considerations-and-best-practices",children:"Key Considerations and Best Practices"}),"\n",(0,s.jsx)(n.h3,{id:"1-version-pinning",children:"1. Version Pinning"}),"\n",(0,s.jsx)(n.p,{children:"Always pin tool versions in both pipelines:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Bash\nbwa 0.7.17\nsamtools 1.18.0\nbcftools 1.18\n\n# Nextflow (container)\ncontainer 'community.wave.seqera.io/library/bwa_samtools:56c9f8d5201889a4'\n# Container hash includes specific versions\n"})}),"\n",(0,s.jsx)(n.h3,{id:"2-handling-floating-point-precision",children:"2. Handling Floating-Point Precision"}),"\n",(0,s.jsx)(n.p,{children:"Some tools produce slightly different floating-point values due to compilation or CPU differences:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# For VCF QUAL scores, allow small differences\ncompare_vcf_quality() {\n    local baseline=$1\n    local migrated=$2\n    local tolerance=0.1\n    \n    # Extract QUAL scores and compare with tolerance\n    paste \\\n        <(grep -v "^#" "$baseline" | awk \'{print $6}\') \\\n        <(grep -v "^#" "$migrated" | awk \'{print $6}\') | \\\n        awk -v tol=$tolerance \'{\n            diff = ($1 - $2)\n            if (diff < 0) diff = -diff\n            if (diff > tol && $1 != ".") {\n                print "DIFFER: " $1 " vs " $2\n            }\n        }\'\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"3-documentation-template",children:"3. Documentation Template"}),"\n",(0,s.jsx)(n.p,{children:"Create a migration checklist:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-markdown",children:"# Pipeline Migration Checklist\n\n## Pre-Migration\n- [ ] Document original bash pipeline\n- [ ] Record all tool versions\n- [ ] Generate baseline MD5 checksums\n- [ ] Test reproducibility (3+ runs)\n- [ ] Identify non-deterministic components\n\n## Migration\n- [ ] Convert each step to Nextflow process\n- [ ] Set seeds for random operations\n- [ ] Configure containerization\n- [ ] Implement resource directives\n- [ ] Add error handling\n\n## Validation\n- [ ] Run Nextflow with same inputs\n- [ ] Generate MD5 checksums\n- [ ] Compare all outputs\n- [ ] Document acceptable differences\n- [ ] Validate on multiple samples\n\n## Sign-Off\n- [ ] All checksums match or differences documented\n- [ ] Code review completed\n- [ ] Team approval\n- [ ] Migration complete\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"summary-confidently-migrating-any-in-house-pipeline-to-enterprise-level",children:"Summary: Confidently Migrating Any In-House Pipeline to Enterprise Level"}),"\n",(0,s.jsx)(n.p,{children:"Whether you're migrating from bash scripts, Python workflows, Snakemake pipelines, custom C++ tools, or anything else, the same 3-step validation framework applies. The MD5-based validation approach is universal and language-agnostic."}),"\n",(0,s.jsx)(n.p,{children:"By following a systematic 3-step approach, you can validate that your new enterprise pipeline produces identical results to your original in-house system:"}),"\n",(0,s.jsx)(n.h3,{id:"step-1-establish-baseline-from-your-original-pipeline",children:"Step 1: Establish Baseline (From Your Original Pipeline)"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Run original pipeline multiple times"}),"\n",(0,s.jsx)(n.li,{children:"Verify determinism (same inputs = same outputs)"}),"\n",(0,s.jsx)(n.li,{children:"Record MD5 checksums of all outputs"}),"\n",(0,s.jsx)(n.li,{children:"Document tool versions and seeds"}),"\n",(0,s.jsx)(n.li,{children:"Works with: bash, Python, Snakemake, custom code, etc."}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"step-2-migrate-with-seed-control-to-your-target-system",children:"Step 2: Migrate with Seed Control (To Your Target System)"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Convert each pipeline step to your target format"}),"\n",(0,s.jsx)(n.li,{children:"Hard-code seeds for random operations"}),"\n",(0,s.jsx)(n.li,{children:"Use containers to match tool versions"}),"\n",(0,s.jsx)(n.li,{children:"Maintain identical resource configurations"}),"\n",(0,s.jsx)(n.li,{children:"Target options: Nextflow, Snakemake, CWL, etc."}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"step-3-validate-with-checksums-automated-or-manual",children:"Step 3: Validate with Checksums (Automated or Manual)"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Run new pipeline with identical inputs"}),"\n",(0,s.jsx)(n.li,{children:"Generate MD5 checksums for all outputs"}),"\n",(0,s.jsx)(n.li,{children:"Compare against baseline"}),"\n",(0,s.jsx)(n.li,{children:"Document acceptable differences"}),"\n",(0,s.jsx)(n.li,{children:"Sign off on migration"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"If targeting Nextflow:"})," Use nf-test to automate steps 2-3 with built-in snapshot management and CI/CD integration."]}),"\n",(0,s.jsx)(n.h3,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"The 3-step framework works for ANY in-house pipeline"})," - Whether you're migrating from bash, Python, Snakemake, or custom code, the MD5-based validation approach is universal"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"MD5 checksums are your source of truth"})," - They provide byte-for-byte verification that outputs are identical, regardless of source or target format"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Reproducibility requires explicit seed control"})," - Any non-deterministic operation must use hard-coded seeds (42 is an arbitrary choice\u2014use what makes sense for your team)"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Version pinning matters"})," - Use containers to guarantee identical tool versions between original and migrated pipelines"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Document everything"})," - Record versions, seeds, checksums, and acceptable differences for your team's understanding"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Validate on multiple samples"})," - Differences might only appear with certain data characteristics or edge cases"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"If migrating TO Nextflow: use nf-test"})," - It automates the entire validation workflow with version-controlled snapshots and CI/CD integration"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Make failures visible"})," - Use ",(0,s.jsx)(n.code,{children:"set -o pipefail"})," and explicit error checking in both pipelines"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Once you've validated that outputs match, you can confidently replace your in-house pipeline with an enterprise system, knowing that you've maintained scientific reproducibility while gaining the benefits of professional workflow management."}),"\n",(0,s.jsx)(n.p,{children:"Your migrated pipeline is now:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Reproducible across teams and platforms"}),"\n",(0,s.jsx)(n.li,{children:"Scalable (to HPC/cloud without modification)"}),"\n",(0,s.jsx)(n.li,{children:"Maintainable by the broader community"}),"\n",(0,s.jsx)(n.li,{children:"Validated against your original implementation"}),"\n",(0,s.jsx)(n.li,{children:"Ready for production and publication"}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},9831(e,n,i){i.d(n,{A:()=>t});const t=i.p+"assets/images/intro-7aaa912f8e48c1bb524eacaf56d8a3cd.png"}}]);