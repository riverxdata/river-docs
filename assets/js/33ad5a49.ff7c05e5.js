"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[1461],{2269(e,i,n){n.r(i),n.d(i,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>r,metadata:()=>s,toc:()=>o});var s=n(6931),t=n(4848),a=n(8453);const r={slug:"intro-ai-ml-bioinformatics-applications",title:"Introduction to AI/ML in Bioinformatics: Classification Models & Evaluation",authors:["river"],tags:["machine-learning","bioinformatics","classification","evaluation","disease-prediction"],image:"./imgs/intro.png"},l=void 0,c={image:n(9831).A,authorsImageUrls:[void 0]},o=[{value:"Real-World Classification Problems in Bioinformatics",id:"real-world-classification-problems-in-bioinformatics",level:2},{value:"Problem 1: Disease Diagnosis from Gene Expression",id:"problem-1-disease-diagnosis-from-gene-expression",level:3},{value:"Problem 2: Protein Function Prediction",id:"problem-2-protein-function-prediction",level:3},{value:"Problem 3: Pathogenic Variant Detection",id:"problem-3-pathogenic-variant-detection",level:3},{value:"Why Build Classification Models? The Power of Automation",id:"why-build-classification-models-the-power-of-automation",level:2},{value:"Part 1: The Simplest Classification Models",id:"part-1-the-simplest-classification-models",level:2},{value:"Setup: Simulated Gene Expression Data",id:"setup-simulated-gene-expression-data",level:3},{value:"Model 1: Rule-Based Classifier (Simplest Possible)",id:"model-1-rule-based-classifier-simplest-possible",level:3},{value:"Model 2: Multi-Gene Mean Classifier",id:"model-2-multi-gene-mean-classifier",level:3},{value:"Model 3: Distance-Based Classifier (Nearest Centroid)",id:"model-3-distance-based-classifier-nearest-centroid",level:3},{value:"Part 2: Evaluating Classification Models",id:"part-2-evaluating-classification-models",level:2},{value:"Key Metrics Explained (Especially for Imbalanced Data)",id:"key-metrics-explained-especially-for-imbalanced-data",level:3},{value:"Understanding Metric Tradeoffs",id:"understanding-metric-tradeoffs",level:2},{value:"Sensitivity vs Specificity Tradeoff",id:"sensitivity-vs-specificity-tradeoff",level:3},{value:"Connecting to Part 1: Building KNN",id:"connecting-to-part-1-building-knn",level:2},{value:"Summary: Key Concepts",id:"summary-key-concepts",level:2},{value:"Confusion Matrix",id:"confusion-matrix",level:3},{value:"Metrics Quick Reference",id:"metrics-quick-reference",level:3},{value:"The Imbalanced Data Problem",id:"the-imbalanced-data-problem",level:3},{value:"Quick Code Reference",id:"quick-code-reference",level:3},{value:"Why This Matters for Bioinformatics",id:"why-this-matters-for-bioinformatics",level:2}];function d(e){const i={a:"a",code:"code",h2:"h2",h3:"h3",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(i.p,{children:"Machine learning is transforming bioinformatics by automating pattern discovery from biological data. But what problems can it actually solve? This post shows real-world applications of classification models, then builds the simplest possible classifiers to understand how they work and how to evaluate them. This is Part 0\u2014the practical foundation before diving into complex algorithms like KNN."}),"\n",(0,t.jsx)(i.h2,{id:"real-world-classification-problems-in-bioinformatics",children:"Real-World Classification Problems in Bioinformatics"}),"\n",(0,t.jsx)(i.p,{children:"Let's start by understanding what classification problems machine learning actually solves:"}),"\n",(0,t.jsx)(i.h3,{id:"problem-1-disease-diagnosis-from-gene-expression",children:"Problem 1: Disease Diagnosis from Gene Expression"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Input"}),": Gene expression levels from patient blood sample"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Output"}),": Normal or Disease (binary classification)"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Real application"}),": Cancer subtypes, Alzheimer's stages, COVID severity"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Goal"}),": Classify new patients into disease categories automatically"]}),"\n"]}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{children:"Patient A: [Gene1=2.3, Gene2=1.5, Gene3=4.2, ...] \u2192 Normal\nPatient B: [Gene1=8.1, Gene2=6.3, Gene3=1.9, ...] \u2192 Disease\nPatient C: [Gene1=3.1, Gene2=2.2, Gene3=5.1, ...] \u2192 Normal\n"})}),"\n",(0,t.jsx)(i.h3,{id:"problem-2-protein-function-prediction",children:"Problem 2: Protein Function Prediction"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Input"}),": Amino acid sequence"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Output"}),": Enzyme, Structural protein, or Transport protein (multi-class)"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Real application"}),": Annotating newly sequenced genomes"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Goal"}),": Predict function of unknown proteins"]}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"problem-3-pathogenic-variant-detection",children:"Problem 3: Pathogenic Variant Detection"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Input"}),": DNA mutation information, population frequency, conservation score"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Output"}),": Pathogenic or Benign (binary classification)"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Real application"}),": Clinical variant interpretation"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Goal"}),": Identify disease-causing mutations from huge variant databases"]}),"\n"]}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.h2,{id:"why-build-classification-models-the-power-of-automation",children:"Why Build Classification Models? The Power of Automation"}),"\n",(0,t.jsx)(i.p,{children:"Before machine learning, biologists manually analyzed data:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:["\u274c ",(0,t.jsx)(i.strong,{children:"Slow"}),": Analyzing 20,000 genes one-by-one takes months"]}),"\n",(0,t.jsxs)(i.li,{children:["\u274c ",(0,t.jsx)(i.strong,{children:"Subjective"}),": Different experts might disagree on classification"]}),"\n",(0,t.jsxs)(i.li,{children:["\u274c ",(0,t.jsx)(i.strong,{children:"Doesn't scale"}),": 10,000 patient samples requires endless manual work"]}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"With ML classification models:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:["\u2705 ",(0,t.jsx)(i.strong,{children:"Fast"}),": Classify 10,000 samples in seconds"]}),"\n",(0,t.jsxs)(i.li,{children:["\u2705 ",(0,t.jsx)(i.strong,{children:"Objective"}),": Same rules applied consistently to every sample"]}),"\n",(0,t.jsxs)(i.li,{children:["\u2705 ",(0,t.jsx)(i.strong,{children:"Scalable"}),": Works for any dataset size without additional effort"]}),"\n"]}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.h2,{id:"part-1-the-simplest-classification-models",children:"Part 1: The Simplest Classification Models"}),"\n",(0,t.jsx)(i.p,{children:"Let's build real but minimal classification models, starting from the simplest to more sophisticated."}),"\n",(0,t.jsx)(i.h3,{id:"setup-simulated-gene-expression-data",children:"Setup: Simulated Gene Expression Data"}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Set seed for reproducibility\nnp.random.seed(42)\n\n# Simulate gene expression data for disease classification\n# 50 normal patients, 50 disease patients\n# 3 genes measured via RNA-seq\n\n# Normal patients: lower expression\nnormal_samples = np.random.normal(loc=5, scale=2, size=(50, 3))\n\n# Disease patients: higher expression (especially gene 1)\ndisease_samples = np.random.normal(loc=8, scale=2, size=(50, 3))\n\n# Combine data\nX = np.vstack([normal_samples, disease_samples])  # Features (gene expression)\ny = np.hstack([np.zeros(50), np.ones(50)])  # Labels (0=normal, 1=disease)\n\n# Create DataFrame for easier inspection\ngene_names = ['Gene_A', 'Gene_B', 'Gene_C']\ndf = pd.DataFrame(X, columns=gene_names)\ndf['Label'] = y\ndf['Label_name'] = df['Label'].map({0: 'Normal', 1: 'Disease'})\n\nprint(\"Gene Expression Data Sample:\")\nprint(df.head(10))\nprint(f\"\\nDataset shape: {X.shape[0]} patients, {X.shape[1]} genes\")\nprint(f\"Classes: {int(sum(y==0))} Normal, {int(sum(y==1))} Disease\")\n\n# Split data: 80% train, 20% test\nsplit_idx = 80\nX_train, X_test = X[:split_idx], X[split_idx:]\ny_train, y_test = y[:split_idx], y[split_idx:]\n\nprint(f\"\\nTraining set: {X_train.shape[0]} samples\")\nprint(f\"Test set: {X_test.shape[0]} samples\")\n"})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.strong,{children:"Output:"})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{children:"Gene Expression Data Sample:\n   Gene_A  Gene_B  Gene_C Label Label_name\n0    4.86    7.02    4.23      0     Normal\n1    5.12    3.54    5.67      0     Normal\n2    3.45    4.89    6.12      0     Normal\n...\nDataset shape: 100 patients, 3 genes\nClasses: 50 Normal, 50 Disease\n\nTraining set: 80 samples\nTest set: 20 samples\n"})}),"\n",(0,t.jsx)(i.h3,{id:"model-1-rule-based-classifier-simplest-possible",children:"Model 1: Rule-Based Classifier (Simplest Possible)"}),"\n",(0,t.jsx)(i.p,{children:"The simplest classifier is just a rule based on one gene:"}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:'class SimpleRuleClassifier:\n    """\n    Classify patients based on a simple threshold rule.\n    If Gene_A > threshold: predict disease\n    Else: predict normal\n    \n    This is how a biologist might manually classify before ML!\n    """\n    def __init__(self, gene_index=0, threshold=6.5):\n        self.gene_index = gene_index\n        self.threshold = threshold\n        self.gene_name = gene_names[gene_index]\n    \n    def predict(self, X):\n        """Make predictions based on simple rule."""\n        predictions = (X[:, self.gene_index] > self.threshold).astype(int)\n        return predictions\n    \n    def __repr__(self):\n        return f"Rule: If {self.gene_name} > {self.threshold}, predict Disease"\n\n# Create and test the rule-based model\nmodel1 = SimpleRuleClassifier(gene_index=0, threshold=6.5)\ny_pred1 = model1.predict(X_test)\n\nprint(f"\\nModel 1: {model1}")\nprint(f"Sample predictions: {y_pred1[:10]}")\n'})}),"\n",(0,t.jsx)(i.h3,{id:"model-2-multi-gene-mean-classifier",children:"Model 2: Multi-Gene Mean Classifier"}),"\n",(0,t.jsx)(i.p,{children:"Slightly better: use the average of all genes:"}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:'class MeanClassifier:\n    """\n    Classify based on mean expression across all genes.\n    If mean(all genes) > threshold: predict disease\n    Else: predict normal\n    \n    This combines information from multiple genes!\n    """\n    def __init__(self, threshold=6.5):\n        self.threshold = threshold\n    \n    def predict(self, X):\n        """Make predictions based on mean expression."""\n        mean_expression = X.mean(axis=1)  # Average across genes\n        predictions = (mean_expression > self.threshold).astype(int)\n        return predictions\n\n# Test mean-based model\nmodel2 = MeanClassifier(threshold=6.5)\ny_pred2 = model2.predict(X_test)\n\nprint(f"\\nModel 2: Mean-based classifier (threshold=6.5)")\nprint(f"Sample predictions: {y_pred2[:10]}")\n'})}),"\n",(0,t.jsx)(i.h3,{id:"model-3-distance-based-classifier-nearest-centroid",children:"Model 3: Distance-Based Classifier (Nearest Centroid)"}),"\n",(0,t.jsx)(i.p,{children:"Even better: find the center of each class, classify by distance:"}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:'class NearestCentroidClassifier:\n    """\n    Classify based on distance to class centroids.\n    \n    Algorithm:\n    1. During training: Calculate mean (centroid) of each class\n    2. During prediction: For new sample, predict class of nearest centroid\n    \n    This is the foundation for more complex algorithms like KNN!\n    Think of it as: "Find which disease type the patient is closest to"\n    """\n    def __init__(self):\n        self.centroids = {}\n    \n    def fit(self, X, y):\n        """Learn the centroid (average) of each class."""\n        for class_label in np.unique(y):\n            self.centroids[class_label] = X[y == class_label].mean(axis=0)\n        print(f"\u2713 Learned {len(self.centroids)} class centroids")\n        print(f"  Normal centroid: {self.centroids[0]}")\n        print(f"  Disease centroid: {self.centroids[1]}")\n    \n    def predict(self, X):\n        """Predict by finding nearest centroid."""\n        predictions = []\n        for sample in X:\n            # Calculate distance to each centroid\n            distances = {}\n            for class_label, centroid in self.centroids.items():\n                # Euclidean distance\n                distance = np.sqrt(np.sum((sample - centroid) ** 2))\n                distances[class_label] = distance\n            \n            # Predict class of nearest centroid\n            prediction = min(distances, key=distances.get)\n            predictions.append(prediction)\n        \n        return np.array(predictions)\n\n# Train and test\nmodel3 = NearestCentroidClassifier()\nmodel3.fit(X_train, y_train)\ny_pred3 = model3.predict(X_test)\n\nprint(f"\\nModel 3: Nearest Centroid Classifier")\nprint(f"Sample predictions: {y_pred3[:10]}")\n'})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.strong,{children:"Output:"})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{children:"\u2713 Learned 2 class centroids\n  Normal centroid: [4.87 4.92 5.11]\n  Disease centroid: [7.98 8.15 8.23]\n\nModel 3: Nearest Centroid Classifier\nSample predictions: [1 1 0 1 0 0 0 0 1 0]\n"})}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.h2,{id:"part-2-evaluating-classification-models",children:"Part 2: Evaluating Classification Models"}),"\n",(0,t.jsx)(i.p,{children:"Now that we have predictions, how do we know which model is good? We need evaluation metrics!"}),"\n",(0,t.jsx)(i.h3,{id:"key-metrics-explained-especially-for-imbalanced-data",children:"Key Metrics Explained (Especially for Imbalanced Data)"}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.strong,{children:"Confusion Matrix"})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{children:"                 Predicted\n                 Disease  Healthy\nActual\nDisease      TP         FN\nHealthy      FP         TN\n"})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.strong,{children:"Definitions:"})}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"TP (True Positive)"}),": Correctly identified disease \u2192 Good! \u2713"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"TN (True Negative)"}),": Correctly identified healthy \u2192 Good! \u2713"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"FP (False Positive)"}),": Healthy person predicted as disease \u2192 False alarm \u2717"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"FN (False Negative)"}),": Disease person predicted as healthy \u2192 Dangerous! \u2717"]}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.strong,{children:"Metrics (Importance for Imbalanced Data):"})}),"\n",(0,t.jsxs)(i.table,{children:[(0,t.jsx)(i.thead,{children:(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.th,{children:"Metric"}),(0,t.jsx)(i.th,{children:"Formula"}),(0,t.jsx)(i.th,{children:"Meaning"}),(0,t.jsx)(i.th,{children:"Best For"})]})}),(0,t.jsxs)(i.tbody,{children:[(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:(0,t.jsx)(i.strong,{children:"Accuracy"})}),(0,t.jsx)(i.td,{children:"(TP+TN)/(TP+TN+FP+FN)"}),(0,t.jsx)(i.td,{children:"Overall correctness"}),(0,t.jsxs)(i.td,{children:["\u274c ",(0,t.jsx)(i.strong,{children:"MISLEADING for imbalanced data"})]})]}),(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:(0,t.jsx)(i.strong,{children:"Sensitivity/Recall"})}),(0,t.jsx)(i.td,{children:"TP/(TP+FN)"}),(0,t.jsx)(i.td,{children:"% of disease cases caught"}),(0,t.jsx)(i.td,{children:"\u2705 Essential for imbalanced data"})]}),(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:(0,t.jsx)(i.strong,{children:"Specificity"})}),(0,t.jsx)(i.td,{children:"TN/(TN+FP)"}),(0,t.jsx)(i.td,{children:"% of healthy cases caught"}),(0,t.jsx)(i.td,{children:"\u2705 Reveals when model ignores minority class"})]}),(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:(0,t.jsx)(i.strong,{children:"Precision"})}),(0,t.jsx)(i.td,{children:"TP/(TP+FP)"}),(0,t.jsx)(i.td,{children:"% of disease predictions correct"}),(0,t.jsx)(i.td,{children:"\u2705 Shows cost of false alarms"})]})]})]}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.strong,{children:"Why Recall + Specificity Matter More Than Accuracy for Imbalanced Data:"})}),"\n",(0,t.jsx)(i.p,{children:"In our test set: 19 disease, 1 healthy (95% disease cases)"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:'Model predicts "disease" for everything'}),"\n",(0,t.jsx)(i.li,{children:"Accuracy = 95% (looks good!)"}),"\n",(0,t.jsx)(i.li,{children:"But Specificity = 0% (completely missed the healthy person!)"}),"\n"]}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"Recall"})," and ",(0,t.jsx)(i.strong,{children:"Specificity"})," immediately show the problem."]}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:'def evaluate_classification(y_true, y_pred, model_name="Model"):\n    """Evaluate a classification model using confusion matrix and metrics."""\n    \n    # Calculate confusion matrix\n    TP = np.sum((y_true == 1) & (y_pred == 1))\n    TN = np.sum((y_true == 0) & (y_pred == 0))\n    FP = np.sum((y_true == 0) & (y_pred == 1))\n    FN = np.sum((y_true == 1) & (y_pred == 0))\n    \n    # Calculate metrics\n    accuracy = (TP + TN) / len(y_true)\n    sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0  # True Positive Rate\n    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0  # True Negative Rate\n    precision = TP / (TP + FP) if (TP + FP) > 0 else 0    # "When we predict disease, are we right?"\n    recall = sensitivity  # Same as sensitivity - "Did we catch disease cases?"\n    \n    # Print results\n    print(f"\\n{\'=\'*70}")\n    print(f"Classification Evaluation: {model_name}")\n    print(f"{\'=\'*70}")\n    print(f"\\nConfusion Matrix:")\n    print(f"  True Positives (TP):   {TP:3d}  \u2192 correctly identified disease patients")\n    print(f"  True Negatives (TN):   {TN:3d}  \u2192 correctly identified healthy people")\n    print(f"  False Positives (FP):  {FP:3d}  \u2192 false alarms (healthy \u2192 disease)")\n    print(f"  False Negatives (FN):  {FN:3d}  \u2192 missed cases (disease \u2192 healthy)")\n    \n    print(f"\\nPerformance Metrics:")\n    print(f"  Accuracy:         {accuracy:.2%}   (overall correctness - MISLEADING for imbalanced data!)")\n    print(f"  Sensitivity/Recall: {recall:.2%}   (disease detection rate - % of disease cases caught)")\n    print(f"  Specificity:      {specificity:.2%}   (healthy detection rate - % of healthy cases caught)")\n    print(f"  Precision:        {precision:.2%}   (positive predictive value - % of disease predictions correct)")\n    \n    # Rating based on both recall and precision\n    if recall >= 0.90 and precision >= 0.90:\n        rating = "\u2713 Excellent classifier"\n    elif recall >= 0.80 and precision >= 0.70:\n        rating = "\u2713 Good classifier"\n    elif recall >= 0.70 or precision >= 0.70:\n        rating = "\u25b3 Acceptable classifier"\n    else:\n        rating = "\u2717 Poor classifier"\n    \n    print(f"  \u2192 {rating}")\n    print(f"\\n  \ud83d\udca1 Insight: High accuracy ({accuracy:.0%}) but low specificity ({specificity:.0%})")\n    print(f"             This shows CLASS IMBALANCE\u2014model predicts disease for almost everything!")\n    \n    return {\n        \'accuracy\': accuracy,\n        \'sensitivity\': recall,\n        \'specificity\': specificity,\n        \'precision\': precision,\n        \'recall\': recall,\n        \'TP\': TP, \'TN\': TN, \'FP\': FP, \'FN\': FN\n    }\n\n# Evaluate all three models\nprint("\\n" + "="*70)\nprint("CLASSIFICATION MODEL COMPARISON")\nprint("="*70)\n\nresults1 = evaluate_classification(y_test, y_pred1, "Model 1: Rule-Based (Gene_A > 6.5)")\nresults2 = evaluate_classification(y_test, y_pred2, "Model 2: Mean-Based Classifier")\nresults3 = evaluate_classification(y_test, y_pred3, "Model 3: Nearest Centroid")\n'})}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.strong,{children:"Output:"})}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{children:"======================================================================\nCLASSIFICATION MODEL COMPARISON\n======================================================================\n\n======================================================================\nClassification Evaluation: Model 1: Rule-Based (Gene_A > 6.5)\n======================================================================\n\nConfusion Matrix:\n  True Positives (TP):    17  \u2192 correctly identified disease patients\n  True Negatives (TN):     0  \u2192 correctly identified healthy people\n  False Positives (FP):    0  \u2192 false alarms (healthy \u2192 disease)\n  False Negatives (FN):    3  \u2192 missed cases (disease \u2192 healthy)\n\nPerformance Metrics:\n  Accuracy:         85.00%   (overall correctness - MISLEADING for imbalanced data!)\n  Sensitivity/Recall: 85.00%   (disease detection rate - % of disease cases caught)\n  Specificity:      0.00%   (healthy detection rate - % of healthy cases caught)\n  Precision:        0.00%   (positive predictive value - % of disease predictions correct)\n  \u2192 \u2717 Poor classifier\n\n  \ud83d\udca1 Insight: High accuracy (85%) but 0% specificity!\n             This shows CLASS IMBALANCE\u2014model predicts disease for almost everything!\n\n======================================================================\nClassification Evaluation: Model 2: Mean-Based Classifier\n======================================================================\n\nConfusion Matrix:\n  True Positives (TP):    19  \u2192 correctly identified disease patients\n  True Negatives (TN):     0  \u2192 correctly identified healthy people\n  False Positives (FP):    0  \u2192 false alarms (healthy \u2192 disease)\n  False Negatives (FN):    1  \u2192 missed cases (disease \u2192 healthy)\n\nPerformance Metrics:\n  Accuracy:         95.00%   (overall correctness - MISLEADING for imbalanced data!)\n  Sensitivity/Recall: 95.00%   (disease detection rate - % of disease cases caught)\n  Specificity:      0.00%   (healthy detection rate - % of healthy cases caught)\n  Precision:       100.00%   (positive predictive value - % of disease predictions correct)\n  \u2192 \u2717 Poor classifier\n\n  \ud83d\udca1 Insight: 95% accuracy + 100% precision looks great, but 0% specificity is a RED FLAG!\n             Model is essentially predicting disease for everyone\u2014it's cheating!\n\n======================================================================\nClassification Evaluation: Model 3: Nearest Centroid\n======================================================================\n\nConfusion Matrix:\n  True Positives (TP):    19  \u2192 correctly identified disease patients\n  True Negatives (TN):     0  \u2192 correctly identified healthy people\n  False Positives (FP):    0  \u2192 false alarms (healthy \u2192 disease)\n  False Negatives (FN):    1  \u2192 missed cases (disease \u2192 healthy)\n\nPerformance Metrics:\n  Accuracy:         95.00%   (overall correctness - MISLEADING for imbalanced data!)\n  Sensitivity/Recall: 95.00%   (disease detection rate - % of disease cases caught)\n  Specificity:      0.00%   (healthy detection rate - % of healthy cases caught)\n  Precision:       100.00%   (positive predictive value - % of disease predictions correct)\n  \u2192 \u2717 Poor classifier\n\n  \ud83d\udca1 Insight: 95% accuracy + 100% precision looks great, but 0% specificity is a RED FLAG!\n             Model is essentially predicting disease for everyone\u2014it's cheating!\n\n**KEY LEARNING:** All three models fail in the same way! They essentially learned the trivial solution:\n\"Predict disease for almost everything.\" This gets 95% accuracy because 95% of the dataset is disease cases.\n\n**Why This Happens with Imbalanced Data:**\n- Naive models learn the easiest shortcut\n- Accuracy rewards predicting the majority class\n- Specificity (or Recall for minority class) immediately exposes this problem!\n"})}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.h2,{id:"understanding-metric-tradeoffs",children:"Understanding Metric Tradeoffs"}),"\n",(0,t.jsx)(i.p,{children:"Different situations require different metrics:"}),"\n",(0,t.jsx)(i.h3,{id:"sensitivity-vs-specificity-tradeoff",children:"Sensitivity vs Specificity Tradeoff"}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.strong,{children:"High Sensitivity (Catch disease):"})}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Better for: Disease screening, diagnostic tests"}),"\n",(0,t.jsx)(i.li,{children:"Accept more false alarms to avoid missing disease"}),"\n",(0,t.jsx)(i.li,{children:"Example: Cancer screening \u2014 missing cancer is worse than false alarms"}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.strong,{children:"High Specificity (Avoid false alarms):"})}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Better for: Confirmatory tests, expensive procedures"}),"\n",(0,t.jsx)(i.li,{children:"Accept missing some cases to avoid unnecessary treatment"}),"\n",(0,t.jsx)(i.li,{children:"Example: Confirming cancer diagnosis before chemotherapy"}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.strong,{children:"Balanced (Youden Index):"})}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Better for: General-purpose classification"}),"\n",(0,t.jsx)(i.li,{children:"No one goal is more important than the other"}),"\n",(0,t.jsx)(i.li,{children:"Example: Gene expression phenotyping"}),"\n"]}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.h2,{id:"connecting-to-part-1-building-knn",children:"Connecting to Part 1: Building KNN"}),"\n",(0,t.jsx)(i.p,{children:"You now understand:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"\u2713 Real classification problems in bioinformatics"}),"\n",(0,t.jsx)(i.li,{children:"\u2713 Simple classification models (rules, means, nearest centroid)"}),"\n",(0,t.jsx)(i.li,{children:"\u2713 How to evaluate models with metrics"}),"\n",(0,t.jsx)(i.li,{children:"\u2713 Sensitivity vs specificity tradeoffs"}),"\n"]}),"\n",(0,t.jsxs)(i.p,{children:[(0,t.jsx)(i.strong,{children:"What's next?"})," In ",(0,t.jsx)(i.a,{href:"/river-docs/blog/machine-learning-bioinformatics-part1-knn",children:"Part 1: Building KNN from Scratch"}),", we'll extend the nearest centroid idea:"]}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Nearest Centroid"}),": Find the 1 closest class center"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"KNN"}),": Find the K closest individual training samples and vote"]}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"The evaluation metrics you learned here apply directly to KNN and all other classifiers!"}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.h2,{id:"summary-key-concepts",children:"Summary: Key Concepts"}),"\n",(0,t.jsx)(i.h3,{id:"confusion-matrix",children:"Confusion Matrix"}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{children:"                 Predicted\n                 Disease  Healthy\nActual\nDisease      TP         FN\nHealthy      FP         TN\n"})}),"\n",(0,t.jsx)(i.h3,{id:"metrics-quick-reference",children:"Metrics Quick Reference"}),"\n",(0,t.jsxs)(i.table,{children:[(0,t.jsx)(i.thead,{children:(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.th,{children:"Metric"}),(0,t.jsx)(i.th,{children:"Formula"}),(0,t.jsx)(i.th,{children:"Meaning"}),(0,t.jsx)(i.th,{children:"When to Use"})]})}),(0,t.jsxs)(i.tbody,{children:[(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:(0,t.jsx)(i.strong,{children:"Accuracy"})}),(0,t.jsx)(i.td,{children:"(TP+TN)/(TP+TN+FP+FN)"}),(0,t.jsx)(i.td,{children:"Overall correctness"}),(0,t.jsx)(i.td,{children:"\u274c Avoid for imbalanced data"})]}),(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:(0,t.jsx)(i.strong,{children:"Sensitivity/Recall"})}),(0,t.jsx)(i.td,{children:"TP/(TP+FN)"}),(0,t.jsx)(i.td,{children:"% of disease cases caught"}),(0,t.jsx)(i.td,{children:"\u2705 Essential for imbalanced data"})]}),(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:(0,t.jsx)(i.strong,{children:"Specificity"})}),(0,t.jsx)(i.td,{children:"TN/(TN+FP)"}),(0,t.jsx)(i.td,{children:"% of healthy cases caught"}),(0,t.jsx)(i.td,{children:"\u2705 Reveals minority class performance"})]}),(0,t.jsxs)(i.tr,{children:[(0,t.jsx)(i.td,{children:(0,t.jsx)(i.strong,{children:"Precision"})}),(0,t.jsx)(i.td,{children:"TP/(TP+FP)"}),(0,t.jsx)(i.td,{children:"% of disease predictions correct"}),(0,t.jsx)(i.td,{children:"\u2705 Cost of false positives"})]})]})]}),"\n",(0,t.jsx)(i.h3,{id:"the-imbalanced-data-problem",children:"The Imbalanced Data Problem"}),"\n",(0,t.jsx)(i.p,{children:"When classes are imbalanced (e.g., 95% disease, 5% healthy):"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Accuracy is misleading"}),': Predicting "disease" for everything gives 95% accuracy']}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Sensitivity/Recall reveals the truth"}),": Shows if model handles majority class"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Specificity shows minority class"}),": Critical for detecting if model fails on rare class"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Precision shows false alarm cost"}),": How many predicted diseases are actually wrong?"]}),"\n"]}),"\n",(0,t.jsxs)(i.p,{children:["\ud83d\udca1 ",(0,t.jsx)(i.strong,{children:"In our example"}),": All models got 95% accuracy but 0% specificity\u2014they're useless!"]}),"\n",(0,t.jsx)(i.h3,{id:"quick-code-reference",children:"Quick Code Reference"}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:"# Calculate confusion matrix\nTP = np.sum((y_true == 1) & (y_pred == 1))\nTN = np.sum((y_true == 0) & (y_pred == 0))\nFP = np.sum((y_true == 0) & (y_pred == 1))\nFN = np.sum((y_true == 1) & (y_pred == 0))\n\n# Calculate metrics for imbalanced data\nsensitivity = TP / (TP + FN)  # Recall - catch disease?\nspecificity = TN / (TN + FP)  # Handle healthy people?\nprecision = TP / (TP + FP)    # When we predict disease, are we right?\naccuracy = (TP + TN) / (TP + TN + FP + FN)  # Don't trust this for imbalanced data!\n"})}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.h2,{id:"why-this-matters-for-bioinformatics",children:"Why This Matters for Bioinformatics"}),"\n",(0,t.jsx)(i.p,{children:"Classification is everywhere in biology:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Disease diagnosis"}),": Predict if patient has disease from omics data"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Protein annotation"}),": Predict protein function from sequence"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Variant interpretation"}),": Predict if mutation is pathogenic"]}),"\n",(0,t.jsxs)(i.li,{children:[(0,t.jsx)(i.strong,{children:"Cell type classification"}),": Predict cell type from gene expression"]}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"But we must evaluate properly:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Different diseases need different metrics"}),"\n",(0,t.jsx)(i.li,{children:"Simple baselines reveal if our model actually learned"}),"\n",(0,t.jsx)(i.li,{children:"Understanding metrics prevents misleading conclusions"}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"You now have the foundation to build, evaluate, and deploy classification models in bioinformatics! \ud83e\uddec\ud83e\udd16"})]})}function h(e={}){const{wrapper:i}={...(0,a.R)(),...e.components};return i?(0,t.jsx)(i,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},9831(e,i,n){n.d(i,{A:()=>s});const s=n.p+"assets/images/intro-7aaa912f8e48c1bb524eacaf56d8a3cd.png"},8453(e,i,n){n.d(i,{R:()=>r,x:()=>l});var s=n(6540);const t={},a=s.createContext(t);function r(e){const i=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function l(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),s.createElement(a.Provider,{value:i},e.children)}},6931(e){e.exports=JSON.parse('{"permalink":"/river-docs/blog/intro-ai-ml-bioinformatics-applications","source":"@site/blog/2026-02/2026-02-01.md","title":"Introduction to AI/ML in Bioinformatics: Classification Models & Evaluation","description":"Machine learning is transforming bioinformatics by automating pattern discovery from biological data. But what problems can it actually solve? This post shows real-world applications of classification models, then builds the simplest possible classifiers to understand how they work and how to evaluate them. This is Part 0\u2014the practical foundation before diving into complex algorithms like KNN.","date":"2026-02-01T00:00:00.000Z","tags":[{"inline":true,"label":"machine-learning","permalink":"/river-docs/blog/tags/machine-learning"},{"inline":true,"label":"bioinformatics","permalink":"/river-docs/blog/tags/bioinformatics"},{"inline":true,"label":"classification","permalink":"/river-docs/blog/tags/classification"},{"inline":true,"label":"evaluation","permalink":"/river-docs/blog/tags/evaluation"},{"inline":true,"label":"disease-prediction","permalink":"/river-docs/blog/tags/disease-prediction"}],"readingTime":11.67,"hasTruncateMarker":true,"authors":[{"name":"Thanh-Giang Tan Nguyen","title":"Founder at RIVER","url":"https://www.facebook.com/nttg8100","page":{"permalink":"/river-docs/blog/authors/river"},"email":"nttg8100@gmail.com","socials":{"linkedin":"https://www.linkedin.com/in/thanh-giang-tan-nguyen-761b28190/","github":"https://github.com/nttg8100"},"imageURL":"https://avatars.githubusercontent.com/u/64969412?v=4","key":"river"}],"frontMatter":{"slug":"intro-ai-ml-bioinformatics-applications","title":"Introduction to AI/ML in Bioinformatics: Classification Models & Evaluation","authors":["river"],"tags":["machine-learning","bioinformatics","classification","evaluation","disease-prediction"],"image":"./imgs/intro.png"},"unlisted":false,"prevItem":{"title":"Machine Learning in Bioinformatics Part 1: Building KNN from Scratch","permalink":"/river-docs/blog/machine-learning-bioinformatics-part1-knn"},"nextItem":{"title":"Bioinformatics Cost Optimization For Input Using Nextflow (Part 2)","permalink":"/river-docs/blog/bioinformatics-computing-resource-optimization-part2"}}')}}]);